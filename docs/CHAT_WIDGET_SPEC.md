# üéôÔ∏è CHAT WIDGET SPECIFICATION
## Garcez Palha - Chat Completo com √Åudio
**Vers√£o**: 1.0 | **Data**: 27/12/2025 | **Status**: ‚ö†Ô∏è ROADMAP - N√ÉO IMPLEMENTADO

---

> **‚ö†Ô∏è IMPORTANTE:** Este documento descreve um widget de chat avan√ßado planejado para o futuro.
> **Status atual:** Site usa links diretos para WhatsApp em todas as p√°ginas.
> **Roadmap:** Chat widget com √°udio ser√° implementado em Q3 2026.

---

## 1. VIS√ÉO GERAL

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                      CHAT WIDGET COMPLETO                            ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                                      ‚ïë
‚ïë   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚ïë
‚ïë   ‚îÇ  üèõÔ∏è Garcez Palha                              [‚îÄ] [‚ñ°] [√ó]  ‚îÇ    ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚ïë
‚ïë   ‚îÇ                                                            ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ü§ñ Clara ‚Ä¢ Online                                         ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ             ‚îÇ    ‚ïë
‚ïë   ‚îÇ                                                            ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îÇ Ol√°! üëã Sou a Clara, assistente da       ‚îÇ üîä 10:30   ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îÇ Garcez Palha. Como posso te ajudar?      ‚îÇ              ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ    ‚ïë
‚ïë   ‚îÇ                                                            ‚îÇ    ‚ïë
‚ïë   ‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ    ‚ïë
‚ïë   ‚îÇ                    ‚îÇ Minha conta foi bloqueada          ‚îÇ ‚îÇ    ‚ïë
‚ïë   ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ    ‚ïë
‚ïë   ‚îÇ                                                            ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îÇ Entendi! Vou te ajudar com isso.         ‚îÇ üîä 10:31   ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îÇ O bloqueio foi judicial ou pelo banco?   ‚îÇ              ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ    ‚ïë
‚ïë   ‚îÇ                                                            ‚îÇ    ‚ïë
‚ïë   ‚îÇ  ‚å®Ô∏è Clara est√° digitando...                                ‚îÇ    ‚ïë
‚ïë   ‚îÇ                                                            ‚îÇ    ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚ïë
‚ïë   ‚îÇ [üìé] [Digite sua mensagem...              ] [üé§] [‚û§]       ‚îÇ    ‚ïë
‚ïë   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ïë
‚ïë                                                                      ‚ïë
‚ïë   FUNCIONALIDADES:                                                   ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ üí¨ Texto: Digita√ß√£o normal                                    ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ üé§ Entrada de √Åudio: Gravar e transcrever                    ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ üîä Sa√≠da de Voz: TTS das respostas                           ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ üìé Anexos: Upload de documentos/imagens                       ‚ïë
‚ïë   ‚îú‚îÄ‚îÄ üìû Chamada: Voz ao vivo (Fase 2)                              ‚ïë
‚ïë   ‚îî‚îÄ‚îÄ üíæ Hist√≥rico: Persistente entre sess√µes                       ‚ïë
‚ïë                                                                      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

---

## 2. ARQUITETURA T√âCNICA

### 2.1 Componentes do Frontend

```
src/components/chat/
‚îú‚îÄ‚îÄ ChatWidget.tsx              # Container principal
‚îú‚îÄ‚îÄ ChatHeader.tsx              # Cabe√ßalho com status
‚îú‚îÄ‚îÄ ChatMessages.tsx            # Lista de mensagens
‚îú‚îÄ‚îÄ ChatMessage.tsx             # Mensagem individual
‚îú‚îÄ‚îÄ ChatInput.tsx               # Input de texto/√°udio
‚îú‚îÄ‚îÄ AudioRecorder.tsx           # Gravador de √°udio
‚îú‚îÄ‚îÄ VoicePlayer.tsx             # Player TTS
‚îú‚îÄ‚îÄ TypingIndicator.tsx         # "Digitando..."
‚îú‚îÄ‚îÄ FileUpload.tsx              # Upload de arquivos
‚îî‚îÄ‚îÄ hooks/
    ‚îú‚îÄ‚îÄ useChat.ts              # Estado do chat
    ‚îú‚îÄ‚îÄ useAudioRecorder.ts     # Grava√ß√£o
    ‚îú‚îÄ‚îÄ useVoicePlayer.ts       # Reprodu√ß√£o TTS
    ‚îî‚îÄ‚îÄ useWebSocket.ts         # Conex√£o real-time
```

### 2.2 Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FLUXO DE √ÅUDIO                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ENTRADA (Usu√°rio ‚Üí Sistema):                                       ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  [Usu√°rio fala] ‚Üí [MediaRecorder] ‚Üí [Blob WAV/WebM]                ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ               [API /api/speech-to-text]                            ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ              [Whisper / AssemblyAI]                                ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ                    [Texto transcrito]                               ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ               [API /api/chat] (mesmo fluxo de texto)               ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  SA√çDA (Sistema ‚Üí Usu√°rio):                                        ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  [Resposta texto] ‚Üí [API /api/text-to-speech]                      ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ              [ElevenLabs / OpenAI TTS]                             ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ                    [Audio MP3/WAV]                                  ‚îÇ
‚îÇ                           ‚îÇ                                         ‚îÇ
‚îÇ                           ‚ñº                                         ‚îÇ
‚îÇ               [VoicePlayer reproduz]                               ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. COMPONENTES DETALHADOS

### 3.1 AudioRecorder.tsx

```tsx
// src/components/chat/AudioRecorder.tsx

import { useState, useRef, useCallback } from 'react';
import { Mic, Square, Loader2 } from 'lucide-react';
import { Button } from '@/components/ui/button';

interface AudioRecorderProps {
  onTranscription: (text: string) => void;
  disabled?: boolean;
}

export function AudioRecorder({ onTranscription, disabled }: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
        await transcribeAudio(audioBlob);
        
        // Parar todas as tracks
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.start(1000); // Chunk a cada 1s
      setIsRecording(true);
      
      // Timer visual
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
      
    } catch (error) {
      console.error('Erro ao iniciar grava√ß√£o:', error);
      alert('N√£o foi poss√≠vel acessar o microfone.');
    }
  }, []);

  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setRecordingTime(0);
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    }
  }, [isRecording]);

  const transcribeAudio = async (audioBlob: Blob) => {
    setIsTranscribing(true);
    
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      
      const response = await fetch('/api/speech-to-text', {
        method: 'POST',
        body: formData,
      });
      
      if (!response.ok) throw new Error('Erro na transcri√ß√£o');
      
      const { text } = await response.json();
      onTranscription(text);
      
    } catch (error) {
      console.error('Erro na transcri√ß√£o:', error);
      alert('N√£o foi poss√≠vel transcrever o √°udio.');
    } finally {
      setIsTranscribing(false);
    }
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="flex items-center gap-2">
      {isTranscribing ? (
        <Button variant="ghost" size="icon" disabled>
          <Loader2 className="h-5 w-5 animate-spin" />
        </Button>
      ) : isRecording ? (
        <>
          <span className="text-red-500 animate-pulse text-sm">
            ‚óè {formatTime(recordingTime)}
          </span>
          <Button 
            variant="destructive" 
            size="icon"
            onClick={stopRecording}
          >
            <Square className="h-4 w-4" />
          </Button>
        </>
      ) : (
        <Button 
          variant="ghost" 
          size="icon"
          onClick={startRecording}
          disabled={disabled}
          title="Gravar √°udio"
        >
          <Mic className="h-5 w-5" />
        </Button>
      )}
    </div>
  );
}
```

### 3.2 VoicePlayer.tsx

```tsx
// src/components/chat/VoicePlayer.tsx

import { useState, useRef, useEffect } from 'react';
import { Volume2, VolumeX, Loader2 } from 'lucide-react';
import { Button } from '@/components/ui/button';

interface VoicePlayerProps {
  text: string;
  messageId: string;
  autoPlay?: boolean;
}

export function VoicePlayer({ text, messageId, autoPlay = false }: VoicePlayerProps) {
  const [isPlaying, setIsPlaying] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  // Gerar √°udio quando necess√°rio
  const generateAudio = async () => {
    if (audioUrl) return audioUrl; // J√° gerado
    
    setIsLoading(true);
    
    try {
      const response = await fetch('/api/text-to-speech', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          text,
          voice: 'clara', // Voz configurada
          messageId,
        }),
      });
      
      if (!response.ok) throw new Error('Erro ao gerar √°udio');
      
      const blob = await response.blob();
      const url = URL.createObjectURL(blob);
      setAudioUrl(url);
      
      return url;
      
    } catch (error) {
      console.error('Erro TTS:', error);
      return null;
    } finally {
      setIsLoading(false);
    }
  };

  const togglePlay = async () => {
    if (isPlaying && audioRef.current) {
      audioRef.current.pause();
      setIsPlaying(false);
      return;
    }
    
    const url = audioUrl || await generateAudio();
    if (!url) return;
    
    if (!audioRef.current) {
      audioRef.current = new Audio(url);
      audioRef.current.onended = () => setIsPlaying(false);
    }
    
    await audioRef.current.play();
    setIsPlaying(true);
  };

  // Autoplay se configurado
  useEffect(() => {
    if (autoPlay && !audioUrl) {
      generateAudio().then(url => {
        if (url) {
          const audio = new Audio(url);
          audio.onended = () => setIsPlaying(false);
          audio.play();
          setIsPlaying(true);
          audioRef.current = audio;
        }
      });
    }
  }, [autoPlay]);

  // Cleanup
  useEffect(() => {
    return () => {
      if (audioUrl) URL.revokeObjectURL(audioUrl);
    };
  }, [audioUrl]);

  return (
    <Button
      variant="ghost"
      size="sm"
      onClick={togglePlay}
      disabled={isLoading}
      className="h-6 w-6 p-0"
      title={isPlaying ? 'Pausar' : 'Ouvir'}
    >
      {isLoading ? (
        <Loader2 className="h-3 w-3 animate-spin" />
      ) : isPlaying ? (
        <VolumeX className="h-3 w-3" />
      ) : (
        <Volume2 className="h-3 w-3" />
      )}
    </Button>
  );
}
```

---

## 4. APIs BACKEND

### 4.1 Speech-to-Text API

```typescript
// src/app/api/speech-to-text/route.ts

import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      return NextResponse.json(
        { error: 'Arquivo de √°udio n√£o fornecido' },
        { status: 400 }
      );
    }
    
    // Converter para formato aceito pelo Whisper
    const buffer = Buffer.from(await audioFile.arrayBuffer());
    
    // Criar File object para a API
    const file = new File([buffer], 'audio.webm', { 
      type: audioFile.type 
    });
    
    // Transcri√ß√£o com Whisper
    const transcription = await openai.audio.transcriptions.create({
      file,
      model: 'whisper-1',
      language: 'pt', // Portugu√™s brasileiro
      response_format: 'text',
    });
    
    return NextResponse.json({
      text: transcription,
      language: 'pt-BR',
    });
    
  } catch (error) {
    console.error('Erro STT:', error);
    return NextResponse.json(
      { error: 'Erro na transcri√ß√£o' },
      { status: 500 }
    );
  }
}

export const config = {
  api: {
    bodyParser: false, // Necess√°rio para FormData
  },
};
```

### 4.2 Text-to-Speech API

```typescript
// src/app/api/text-to-speech/route.ts

import { NextRequest, NextResponse } from 'next/server';

// Op√ß√£o 1: OpenAI TTS
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Op√ß√£o 2: ElevenLabs (melhor qualidade)
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const ELEVENLABS_VOICE_ID = process.env.ELEVENLABS_VOICE_ID || 'EXAVITQu4vr4xnSDxMaL'; // Bella

export async function POST(request: NextRequest) {
  try {
    const { text, voice = 'clara', provider = 'openai' } = await request.json();
    
    if (!text) {
      return NextResponse.json(
        { error: 'Texto n√£o fornecido' },
        { status: 400 }
      );
    }
    
    let audioBuffer: Buffer;
    
    if (provider === 'elevenlabs') {
      // ElevenLabs - Qualidade superior
      const response = await fetch(
        `https://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}`,
        {
          method: 'POST',
          headers: {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': ELEVENLABS_API_KEY!,
          },
          body: JSON.stringify({
            text,
            model_id: 'eleven_multilingual_v2',
            voice_settings: {
              stability: 0.5,
              similarity_boost: 0.75,
            }
          }),
        }
      );
      
      if (!response.ok) throw new Error('ElevenLabs error');
      
      audioBuffer = Buffer.from(await response.arrayBuffer());
      
    } else {
      // OpenAI TTS - Mais barato
      const mp3 = await openai.audio.speech.create({
        model: 'tts-1',
        voice: 'nova', // Voz feminina brasileira-friendly
        input: text,
        response_format: 'mp3',
      });
      
      audioBuffer = Buffer.from(await mp3.arrayBuffer());
    }
    
    // Retornar √°udio
    return new NextResponse(audioBuffer, {
      headers: {
        'Content-Type': 'audio/mpeg',
        'Content-Length': audioBuffer.length.toString(),
      },
    });
    
  } catch (error) {
    console.error('Erro TTS:', error);
    return NextResponse.json(
      { error: 'Erro na s√≠ntese de voz' },
      { status: 500 }
    );
  }
}
```

---

## 5. CHAT INPUT COMPLETO

### 5.1 ChatInput.tsx

```tsx
// src/components/chat/ChatInput.tsx

import { useState, useRef, FormEvent, KeyboardEvent } from 'react';
import { Send, Paperclip, Mic, Loader2 } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { AudioRecorder } from './AudioRecorder';
import { FileUpload } from './FileUpload';

interface ChatInputProps {
  onSendMessage: (message: string, files?: File[]) => Promise<void>;
  disabled?: boolean;
  placeholder?: string;
}

export function ChatInput({ 
  onSendMessage, 
  disabled,
  placeholder = 'Digite sua mensagem...' 
}: ChatInputProps) {
  const [message, setMessage] = useState('');
  const [isSending, setIsSending] = useState(false);
  const [files, setFiles] = useState<File[]>([]);
  const textareaRef = useRef<HTMLTextAreaElement>(null);

  const handleSubmit = async (e?: FormEvent) => {
    e?.preventDefault();
    
    const trimmedMessage = message.trim();
    if (!trimmedMessage && files.length === 0) return;
    
    setIsSending(true);
    
    try {
      await onSendMessage(trimmedMessage, files.length > 0 ? files : undefined);
      setMessage('');
      setFiles([]);
      textareaRef.current?.focus();
    } finally {
      setIsSending(false);
    }
  };

  const handleKeyDown = (e: KeyboardEvent<HTMLTextAreaElement>) => {
    // Enter para enviar, Shift+Enter para nova linha
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  };

  const handleTranscription = (text: string) => {
    setMessage(prev => prev + (prev ? ' ' : '') + text);
    textareaRef.current?.focus();
  };

  const handleFilesSelected = (newFiles: File[]) => {
    setFiles(prev => [...prev, ...newFiles]);
  };

  const removeFile = (index: number) => {
    setFiles(prev => prev.filter((_, i) => i !== index));
  };

  return (
    <div className="border-t p-4">
      {/* Preview de arquivos */}
      {files.length > 0 && (
        <div className="flex flex-wrap gap-2 mb-2">
          {files.map((file, index) => (
            <div 
              key={index}
              className="flex items-center gap-1 bg-muted px-2 py-1 rounded text-sm"
            >
              <span className="truncate max-w-[150px]">{file.name}</span>
              <button 
                onClick={() => removeFile(index)}
                className="text-muted-foreground hover:text-foreground"
              >
                √ó
              </button>
            </div>
          ))}
        </div>
      )}
      
      {/* Input principal */}
      <form onSubmit={handleSubmit} className="flex items-end gap-2">
        {/* Upload de arquivo */}
        <FileUpload onFilesSelected={handleFilesSelected}>
          <Button 
            type="button"
            variant="ghost" 
            size="icon"
            disabled={disabled}
            title="Anexar arquivo"
          >
            <Paperclip className="h-5 w-5" />
          </Button>
        </FileUpload>
        
        {/* Textarea */}
        <div className="flex-1 relative">
          <Textarea
            ref={textareaRef}
            value={message}
            onChange={(e) => setMessage(e.target.value)}
            onKeyDown={handleKeyDown}
            placeholder={placeholder}
            disabled={disabled || isSending}
            className="min-h-[44px] max-h-[120px] resize-none pr-10"
            rows={1}
          />
        </div>
        
        {/* Gravador de √°udio */}
        <AudioRecorder 
          onTranscription={handleTranscription}
          disabled={disabled || isSending}
        />
        
        {/* Bot√£o enviar */}
        <Button 
          type="submit"
          size="icon"
          disabled={disabled || isSending || (!message.trim() && files.length === 0)}
        >
          {isSending ? (
            <Loader2 className="h-5 w-5 animate-spin" />
          ) : (
            <Send className="h-5 w-5" />
          )}
        </Button>
      </form>
    </div>
  );
}
```

---

## 6. MENSAGEM COM PLAYER DE VOZ

### 6.1 ChatMessage.tsx

```tsx
// src/components/chat/ChatMessage.tsx

import { cn } from '@/lib/utils';
import { VoicePlayer } from './VoicePlayer';
import { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';
import { format } from 'date-fns';
import { ptBR } from 'date-fns/locale';

interface ChatMessageProps {
  message: {
    id: string;
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date;
    attachments?: Attachment[];
  };
  showVoice?: boolean;
  autoPlayVoice?: boolean;
}

interface Attachment {
  type: 'image' | 'document';
  url: string;
  name: string;
}

export function ChatMessage({ 
  message, 
  showVoice = true,
  autoPlayVoice = false 
}: ChatMessageProps) {
  const isUser = message.role === 'user';
  
  return (
    <div className={cn(
      'flex gap-3 p-4',
      isUser ? 'flex-row-reverse' : 'flex-row'
    )}>
      {/* Avatar */}
      <Avatar className="h-8 w-8 shrink-0">
        {isUser ? (
          <AvatarFallback>U</AvatarFallback>
        ) : (
          <>
            <AvatarImage src="/clara-avatar.png" alt="Clara" />
            <AvatarFallback>C</AvatarFallback>
          </>
        )}
      </Avatar>
      
      {/* Conte√∫do */}
      <div className={cn(
        'flex flex-col max-w-[80%]',
        isUser ? 'items-end' : 'items-start'
      )}>
        {/* Bal√£o de mensagem */}
        <div className={cn(
          'rounded-2xl px-4 py-2',
          isUser 
            ? 'bg-primary text-primary-foreground' 
            : 'bg-muted'
        )}>
          {/* Texto */}
          <p className="whitespace-pre-wrap">{message.content}</p>
          
          {/* Anexos */}
          {message.attachments && message.attachments.length > 0 && (
            <div className="mt-2 flex flex-col gap-2">
              {message.attachments.map((att, i) => (
                att.type === 'image' ? (
                  <img 
                    key={i}
                    src={att.url} 
                    alt={att.name}
                    className="max-w-[200px] rounded"
                  />
                ) : (
                  <a 
                    key={i}
                    href={att.url}
                    target="_blank"
                    className="text-sm underline"
                  >
                    üìé {att.name}
                  </a>
                )
              ))}
            </div>
          )}
        </div>
        
        {/* Footer: hora + player */}
        <div className="flex items-center gap-2 mt-1 text-xs text-muted-foreground">
          <span>
            {format(message.timestamp, 'HH:mm', { locale: ptBR })}
          </span>
          
          {/* Player de voz apenas para mensagens do assistente */}
          {!isUser && showVoice && (
            <VoicePlayer 
              text={message.content}
              messageId={message.id}
              autoPlay={autoPlayVoice}
            />
          )}
        </div>
      </div>
    </div>
  );
}
```

---

## 7. CONFIGURA√á√ïES E PREFER√äNCIAS

### 7.1 Configura√ß√µes do Usu√°rio

```typescript
// src/lib/chat/settings.ts

export interface ChatSettings {
  // √Åudio
  autoPlayVoice: boolean;        // Tocar voz automaticamente
  voiceEnabled: boolean;         // Habilitar TTS
  voiceSpeed: number;            // Velocidade (0.5-2.0)
  voiceVolume: number;           // Volume (0-1)
  
  // Notifica√ß√µes
  soundEnabled: boolean;         // Som de notifica√ß√£o
  desktopNotifications: boolean; // Notifica√ß√µes push
  
  // Interface
  compactMode: boolean;          // Modo compacto
  darkMode: boolean;             // Tema escuro
  fontSize: 'small' | 'medium' | 'large';
  
  // Privacidade
  saveHistory: boolean;          // Salvar hist√≥rico
  typingIndicator: boolean;      // Mostrar "digitando"
}

export const DEFAULT_SETTINGS: ChatSettings = {
  autoPlayVoice: false,
  voiceEnabled: true,
  voiceSpeed: 1.0,
  voiceVolume: 0.8,
  soundEnabled: true,
  desktopNotifications: false,
  compactMode: false,
  darkMode: false,
  fontSize: 'medium',
  saveHistory: true,
  typingIndicator: true,
};

// Persistir no localStorage
export function saveSettings(settings: Partial<ChatSettings>) {
  const current = loadSettings();
  const updated = { ...current, ...settings };
  localStorage.setItem('chat_settings', JSON.stringify(updated));
  return updated;
}

export function loadSettings(): ChatSettings {
  try {
    const saved = localStorage.getItem('chat_settings');
    if (saved) {
      return { ...DEFAULT_SETTINGS, ...JSON.parse(saved) };
    }
  } catch (e) {}
  return DEFAULT_SETTINGS;
}
```

### 7.2 Componente de Configura√ß√µes

```tsx
// src/components/chat/ChatSettings.tsx

import { useState } from 'react';
import { Settings } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Switch } from '@/components/ui/switch';
import { Slider } from '@/components/ui/slider';
import {
  Sheet,
  SheetContent,
  SheetHeader,
  SheetTitle,
  SheetTrigger,
} from '@/components/ui/sheet';
import { ChatSettings, saveSettings, loadSettings } from '@/lib/chat/settings';

export function ChatSettingsPanel() {
  const [settings, setSettings] = useState<ChatSettings>(loadSettings);

  const updateSetting = <K extends keyof ChatSettings>(
    key: K, 
    value: ChatSettings[K]
  ) => {
    const updated = saveSettings({ [key]: value });
    setSettings(updated);
  };

  return (
    <Sheet>
      <SheetTrigger asChild>
        <Button variant="ghost" size="icon">
          <Settings className="h-5 w-5" />
        </Button>
      </SheetTrigger>
      
      <SheetContent>
        <SheetHeader>
          <SheetTitle>Configura√ß√µes do Chat</SheetTitle>
        </SheetHeader>
        
        <div className="space-y-6 mt-6">
          {/* √Åudio */}
          <div className="space-y-4">
            <h3 className="font-medium">√Åudio</h3>
            
            <div className="flex items-center justify-between">
              <span>Voz habilitada</span>
              <Switch
                checked={settings.voiceEnabled}
                onCheckedChange={(v) => updateSetting('voiceEnabled', v)}
              />
            </div>
            
            <div className="flex items-center justify-between">
              <span>Reproduzir automaticamente</span>
              <Switch
                checked={settings.autoPlayVoice}
                onCheckedChange={(v) => updateSetting('autoPlayVoice', v)}
                disabled={!settings.voiceEnabled}
              />
            </div>
            
            <div className="space-y-2">
              <span>Velocidade da voz</span>
              <Slider
                value={[settings.voiceSpeed]}
                onValueChange={([v]) => updateSetting('voiceSpeed', v)}
                min={0.5}
                max={2}
                step={0.1}
                disabled={!settings.voiceEnabled}
              />
            </div>
          </div>
          
          {/* Notifica√ß√µes */}
          <div className="space-y-4">
            <h3 className="font-medium">Notifica√ß√µes</h3>
            
            <div className="flex items-center justify-between">
              <span>Sons</span>
              <Switch
                checked={settings.soundEnabled}
                onCheckedChange={(v) => updateSetting('soundEnabled', v)}
              />
            </div>
            
            <div className="flex items-center justify-between">
              <span>Notifica√ß√µes desktop</span>
              <Switch
                checked={settings.desktopNotifications}
                onCheckedChange={(v) => updateSetting('desktopNotifications', v)}
              />
            </div>
          </div>
          
          {/* Privacidade */}
          <div className="space-y-4">
            <h3 className="font-medium">Privacidade</h3>
            
            <div className="flex items-center justify-between">
              <span>Salvar hist√≥rico</span>
              <Switch
                checked={settings.saveHistory}
                onCheckedChange={(v) => updateSetting('saveHistory', v)}
              />
            </div>
          </div>
        </div>
      </SheetContent>
    </Sheet>
  );
}
```

---

## 8. CUSTO ESTIMADO

### 8.1 Tabela de Custos

| Servi√ßo | Custo | Volume Esperado | Custo Mensal |
|---------|-------|-----------------|--------------|
| **Whisper (STT)** | $0.006/min | 500 min/m√™s | $3.00 |
| **OpenAI TTS** | $0.015/1k chars | 100k chars/m√™s | $1.50 |
| **ElevenLabs** | $22/m√™s | - | $22.00 |
| **Total (OpenAI)** | - | - | ~$4.50/m√™s |
| **Total (ElevenLabs)** | - | - | ~$25/m√™s |

### 8.2 Otimiza√ß√µes de Custo

```typescript
// Estrat√©gias para reduzir custos:

// 1. Cache de √°udio gerado
const audioCache = new Map<string, string>();

async function getOrGenerateAudio(text: string, messageId: string) {
  const cacheKey = `${messageId}_${text.substring(0, 50)}`;
  
  if (audioCache.has(cacheKey)) {
    return audioCache.get(cacheKey)!;
  }
  
  const audioUrl = await generateAudio(text);
  audioCache.set(cacheKey, audioUrl);
  
  return audioUrl;
}

// 2. Gerar √°udio apenas sob demanda (n√£o autoplay)
// 3. Limitar tamanho do texto para TTS (max 500 chars)
// 4. Comprimir √°udio antes de enviar para transcri√ß√£o
```

---

## 9. CHECKLIST DE IMPLEMENTA√á√ÉO

### Fase 1: Grava√ß√£o de √Åudio (3-4h)
- [ ] Componente AudioRecorder
- [ ] API /api/speech-to-text
- [ ] Integra√ß√£o com Whisper
- [ ] Indicador visual de grava√ß√£o
- [ ] Teste em mobile e desktop

### Fase 2: Text-to-Speech (2-3h)
- [ ] Componente VoicePlayer
- [ ] API /api/text-to-speech
- [ ] Integra√ß√£o com OpenAI TTS ou ElevenLabs
- [ ] Bot√£o de play em cada mensagem
- [ ] Configura√ß√£o de autoplay

### Fase 3: Chat Input Completo (2-3h)
- [ ] ChatInput com texto + √°udio
- [ ] Upload de arquivos
- [ ] Preview de anexos
- [ ] Atalhos de teclado

### Fase 4: Configura√ß√µes (1-2h)
- [ ] Painel de configura√ß√µes
- [ ] Persist√™ncia em localStorage
- [ ] Prefer√™ncias de voz

### Fase 5: Polimento (2-3h)
- [ ] Testes de usabilidade
- [ ] Otimiza√ß√£o de performance
- [ ] Cache de √°udio
- [ ] Fallbacks de erro

**TOTAL: 10-15 horas**

---

*Documento criado em 27/12/2025*
*Vers√£o 1.0 - DRAFT*
