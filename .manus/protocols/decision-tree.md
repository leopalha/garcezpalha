# PROTOCOLO: Decision Tree MANUS v7.0

**VersÃ£o**: 1.0
**Data**: 29/12/2025
**Sistema**: MANUS v7.0 (Multi-Agent Network for Unified Systems)
**Projeto**: Garcez Palha - Advocacia Digital

---

## ÃNDICE

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Ãrvore de DecisÃµes Principal](#Ã¡rvore-de-decisÃµes-principal)
3. [Comandos e AÃ§Ãµes](#comandos-e-aÃ§Ãµes)
4. [Quando Usar Task Tool](#quando-usar-task-tool)
5. [Fluxogramas de DecisÃ£o](#fluxogramas-de-decisÃ£o)
6. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)

---

## VISÃƒO GERAL

### O que Ã© a Decision Tree?

A **Decision Tree** Ã© o mapeamento completo de comandos â†’ aÃ§Ãµes automÃ¡ticas do MANUS v7.0.

Define:
- Que arquivos ler para cada comando
- Que tools usar em cada situaÃ§Ã£o
- Quando executar diretamente vs usar Task tool
- SequÃªncia de aÃ§Ãµes para cada cenÃ¡rio

### Por que usar?

**BenefÃ­cios:**
- ğŸš€ **Velocidade:** MANUS nÃ£o precisa "pensar", jÃ¡ sabe o que fazer
- ğŸ¯ **ConsistÃªncia:** Mesmo comando sempre gera mesma aÃ§Ã£o
- ğŸ“Š **Previsibilidade:** UsuÃ¡rio sabe o que esperar
- âš¡ **AutomaÃ§Ã£o:** Reduz decisÃµes manuais

### PrincÃ­pio fundamental

```
Se comando X
  EntÃ£o aÃ§Ã£o Y
  Com tools Z
  Resultando em output W
```

---

## ÃRVORE DE DECISÃ•ES PRINCIPAL

### Diagrama ASCII

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DECISION TREE - MANUS v7.0                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTRADA: Comando do usuÃ¡rio
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLASSIFICAÃ‡ÃƒO DO COMANDO                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  1. AUDITORIA â†’ Agent Loop (protocolo agent-loop.md)                    â”‚
â”‚  2. IMPLEMENTAÃ‡ÃƒO â†’ ExecuÃ§Ã£o direta ou Task                             â”‚
â”‚  3. GERAÃ‡ÃƒO DE TASKS â†’ Task Generation (protocolo task-generation.md)  â”‚
â”‚  4. VALIDAÃ‡ÃƒO â†’ ValidaÃ§Ã£o especÃ­fica                                    â”‚
â”‚  5. CRIAÃ‡ÃƒO â†’ CriaÃ§Ã£o especÃ­fica                                        â”‚
â”‚  6. INFORMAÃ‡ÃƒO â†’ Leitura e resposta                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚               â”‚              â”‚              â”‚              â”‚
    â–¼               â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚AUDITORIAâ”‚    â”‚IMPLEMENTAâ”‚  â”‚GERAÃ‡ÃƒO   â”‚  â”‚VALIDAÃ‡ÃƒO â”‚  â”‚INFORMAÃ‡ÃƒOâ”‚
â”‚        â”‚    â”‚Ã‡ÃƒO       â”‚  â”‚TASKS     â”‚  â”‚          â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚               â”‚              â”‚              â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                        SAÃDA: AÃ§Ã£o executada
```

---

## COMANDOS E AÃ‡Ã•ES

### 1. AUDITORIA

**Comandos que ativam:**
```
- "audite a documentaÃ§Ã£o"
- "verifique alinhamento cÃ³digo-docs"
- "qual o score da documentaÃ§Ã£o?"
- "identifique gaps"
- "anÃ¡lise completa do projeto"
```

**AÃ§Ã£o automÃ¡tica:**
```
PROTOCOLO: agent-loop.md
FASES: ANALYZE â†’ PLAN â†’ EXECUTE â†’ OBSERVE â†’ ITERATE â†’ DELIVER
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
1. .manus/knowledge/INDEX.md
2. .manus/knowledge/produtos-catalogo.md
3. .manus/knowledge/pages-implementadas.md
4. .manus/knowledge/agentes-juridicos.md
5. .manus/knowledge/compliance-oab.md
6. .manus/knowledge/tech-stack.md
7. docs/tasks.md (se existir)
8. src/lib/products/catalog.ts
9. src/app/(marketing)/solucoes/ (via Glob)
```

**Tools a usar:**
```
1. Read (10-20x) - Ler documentos
2. Glob (3-5x) - Listar arquivos
3. Grep (5-10x) - Buscar padrÃµes
4. Bash (2-5x) - Git status, ls, wc
5. Write (2-4x) - Criar relatÃ³rios
6. TodoWrite (1x) - Criar lista de tarefas
```

**Output esperado:**
```
1. .manus/AUDITORIA_COMPLETA_MANUS.md
2. .manus/GAPS_E_INCONSISTENCIAS.md
3. Score: X/100 (classificaÃ§Ã£o)
4. PrÃ³ximos passos priorizados
```

**Tempo estimado:** 30-60 minutos (ANALYZE) + 5-14h (loop completo)

**DecisÃ£o: Usar Task tool?**
```
NÃƒO - Executar diretamente (MANUS faz auditoria)
```

---

### 2. IMPLEMENTAÃ‡ÃƒO

#### 2.1. Implementar feature especÃ­fica

**Comandos que ativam:**
```
- "implemente a feature X"
- "crie a pÃ¡gina Y"
- "adicione funcionalidade Z"
- "corrija bug W"
```

**DecisÃ£o: Usar Task tool?**
```
SE esforÃ§o estimado > 4 horas E tarefa tem escopo claro
  ENTÃƒO usar Task tool (sub-agent implementa)
SENÃƒO
  Executar diretamente (MANUS implementa)
```

**Arquivos a ler (depende da feature):**
```
SE feature = "criar pÃ¡gina produto X"
  1. .manus/knowledge/produtos-catalogo.md (verificar produto existe)
  2. src/lib/products/catalog.ts (pegar dados do produto)
  3. src/lib/products/vsl-config.ts (ver se precisa config)
  4. src/app/(marketing)/solucoes/[category]/[slug]/page.tsx (template)

SE feature = "criar agent Y"
  1. src/lib/ai/agents/ (listar agents existentes)
  2. src/lib/ai/agents/base-agent.ts (estrutura base)
  3. .manus/knowledge/agentes-juridicos.md (documentaÃ§Ã£o)

SE feature = "criar campanha Ads Z"
  1. .manus/knowledge/produtos-catalogo.md (dados produto)
  2. docs/25-GOOGLE-ADS-CAMPANHAS.md (campanhas existentes)
  3. .manus/knowledge/compliance-oab.md (validar copy)
```

**Tools a usar:**
```
1. Read (5-15x) - Ler arquivos relevantes
2. Glob/Grep (2-5x) - Buscar padrÃµes
3. Edit OU Write (3-10x) - Implementar
4. Task (0-1x) - LanÃ§ar sub-agent se esforÃ§o > 4h
5. TodoWrite (1x) - Atualizar progresso
```

**Output esperado:**
```
1. Arquivos criados/editados conforme solicitado
2. ValidaÃ§Ã£o de funcionamento
3. AtualizaÃ§Ã£o de documentaÃ§Ã£o (se aplicÃ¡vel)
4. Commit git (se usuÃ¡rio solicitar)
```

**Tempo estimado:** 30min - 8h (varia muito)

---

#### 2.2. Implementar mÃºltiplas features

**Comandos que ativam:**
```
- "implemente as features X, Y e Z"
- "crie pÃ¡ginas para todos os produtos da categoria W"
- "adicione VSLs customizadas para top 10 produtos"
```

**DecisÃ£o: Usar Task tool?**
```
SE nÃºmero de features >= 3 E features sÃ£o independentes
  ENTÃƒO usar Task tool (1 sub-agent por feature em paralelo)
SENÃƒO SE features sÃ£o interdependentes
  Executar sequencialmente (MANUS faz uma por vez)
```

**Exemplo:**
```
Comando: "Crie pÃ¡ginas para 5 produtos criminais"

DecisÃ£o:
- Features: 5 (>= 3)
- Independentes: SIM (cada pÃ¡gina Ã© independente)
- EsforÃ§o total: 10h (2h por pÃ¡gina)
â†’ Usar Task tool (5 sub-agents em paralelo)
```

---

### 3. GERAÃ‡ÃƒO DE TASKS

**Comandos que ativam:**
```
- "gere tasks"
- "crie tasks.md"
- "liste prÃ³ximos passos"
- "o que fazer agora?"
- "roadmap de prÃ³ximas features"
- "apÃ³s auditoria, o que implementar?"
```

**AÃ§Ã£o automÃ¡tica:**
```
PROTOCOLO: task-generation.md
FASES: LEITURA â†’ ANÃLISE â†’ GERAÃ‡ÃƒO â†’ PRIORIZAÃ‡ÃƒO â†’ OUTPUT
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
1. .manus/knowledge/INDEX.md
2. .manus/knowledge/produtos-catalogo.md
3. .manus/knowledge/pages-implementadas.md
4. .manus/knowledge/agentes-juridicos.md
5. .manus/knowledge/compliance-oab.md
6. docs/tasks.md (se existir)
7. src/lib/products/catalog.ts
8. .manus/GAPS_E_INCONSISTENCIAS.md (se auditoria foi feita)
```

**Tools a usar:**
```
1. Read (6-10x) - Ler knowledge base
2. Grep (2-5x) - Identificar gaps
3. Write (1x) - Criar/atualizar docs/tasks.md
4. TodoWrite (1x) - Opcional (se usuÃ¡rio pedir tracking)
```

**Output esperado:**
```
1. docs/tasks.md atualizado
2. Resumo executivo (total tasks, P0/P1/P2, esforÃ§o)
3. Roadmap de 3 sprints
4. MÃ©tricas de sucesso
```

**Tempo estimado:** 5-15 minutos

**DecisÃ£o: Usar Task tool?**
```
NÃƒO - Executar diretamente (task generation Ã© rÃ¡pida)
```

---

### 4. VALIDAÃ‡ÃƒO

#### 4.1. Validar alinhamento cÃ³digo-docs

**Comandos que ativam:**
```
- "valide alinhamento cÃ³digo-documentaÃ§Ã£o"
- "verifique se docs refletem cÃ³digo"
- "cross-check implementaÃ§Ã£o vs documentaÃ§Ã£o"
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
1. .manus/knowledge/produtos-catalogo.md (57 produtos documentados)
2. src/lib/products/catalog.ts (produtos implementados)
3. .manus/knowledge/pages-implementadas.md (pÃ¡ginas documentadas)
4. src/app/(marketing)/solucoes/ (pÃ¡ginas implementadas - via Glob)
5. .manus/knowledge/agentes-juridicos.md (23 agentes documentados)
6. src/lib/ai/agents/ (agentes implementados - via Glob)
```

**Tools a usar:**
```
1. Read (6-10x)
2. Glob (3-5x) - Listar arquivos .tsx, .ts
3. Grep (5-10x) - Buscar padrÃµes
4. Write (1x) - Criar relatÃ³rio de validaÃ§Ã£o
```

**Output esperado:**
```
1. .manus/VALIDACAO_ALINHAMENTO.md
2. Lista de inconsistÃªncias encontradas (se houver)
3. Score de alinhamento: X% (meta: 100%)
```

**Tempo estimado:** 10-20 minutos

**DecisÃ£o: Usar Task tool?**
```
NÃƒO - Executar diretamente (validaÃ§Ã£o Ã© anÃ¡lise, nÃ£o implementaÃ§Ã£o)
```

---

#### 4.2. Validar compliance OAB

**Comandos que ativam:**
```
- "valide compliance OAB"
- "verifique se hÃ¡ frases proibidas"
- "audite conteÃºdo contra regras da OAB"
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
1. .manus/knowledge/compliance-oab.md (40 frases proibidas)
2. src/app/(marketing)/solucoes/ (todas as pÃ¡ginas - via Glob)
3. src/lib/products/vsl-config.ts (VSLs customizadas)
4. docs/24-LANDING-PAGE-PRINCIPAL.md (se existir)
5. docs/25-GOOGLE-ADS-CAMPANHAS.md (se existir)
```

**Tools a usar:**
```
1. Read (1x) - Ler compliance-oab.md
2. Glob (1x) - Listar todas as pÃ¡ginas .tsx
3. Grep (40x) - Buscar cada frase proibida em todos os arquivos
4. Write (1x) - Criar relatÃ³rio de compliance
```

**Output esperado:**
```
1. .manus/VALIDACAO_COMPLIANCE_OAB.md
2. Lista de violaÃ§Ãµes encontradas (se houver)
3. Status: âœ… COMPLIANT ou âŒ VIOLAÃ‡Ã•ES ENCONTRADAS
```

**Tempo estimado:** 10-15 minutos

**DecisÃ£o: Usar Task tool?**
```
NÃƒO - Executar diretamente (validaÃ§Ã£o automÃ¡tica via Grep)
```

---

### 5. CRIAÃ‡ÃƒO

#### 5.1. Criar pÃ¡gina de produto

**Comandos que ativam:**
```
- "crie pÃ¡gina para produto X"
- "gere VSL para produto Y"
- "adicione produto Z ao site"
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
1. .manus/knowledge/produtos-catalogo.md (verificar produto existe)
2. src/lib/products/catalog.ts (dados do produto)
3. src/lib/products/vsl-config.ts (ver padrÃ£o de VSL)
4. .manus/knowledge/compliance-oab.md (validar copy)
5. src/app/(marketing)/solucoes/[category]/[slug]/page.tsx (template)
```

**Tools a usar:**
```
1. Read (5x) - Ler arquivos relevantes
2. Edit (1-2x) - Adicionar config em vsl-config.ts
3. Grep (1x) - Verificar se produto jÃ¡ tem pÃ¡gina
4. Write (0-1x) - Criar arquivo se necessÃ¡rio (roteamento dinÃ¢mico jÃ¡ existe)
```

**Output esperado:**
```
1. Produto adicionado/validado em catalog.ts
2. VSL config criada em vsl-config.ts
3. PÃ¡gina acessÃ­vel em /solucoes/[category]/[slug]
4. Compliance OAB validado
```

**Tempo estimado:** 1-2 horas

**DecisÃ£o: Usar Task tool?**
```
SE criar 1 pÃ¡gina
  NÃƒO - Executar diretamente
SE criar 3+ pÃ¡ginas
  SIM - Usar Task tool (1 agent por pÃ¡gina)
```

---

#### 5.2. Criar campanha Google Ads

**Comandos que ativam:**
```
- "crie campanha Google Ads para produto X"
- "gere anÃºncios para produto Y"
- "configure Ads para categoria Z"
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
1. .manus/knowledge/produtos-catalogo.md (dados do produto)
2. .manus/knowledge/compliance-oab.md (validar copy dos anÃºncios)
3. docs/25-GOOGLE-ADS-CAMPANHAS.md (campanhas existentes - padrÃ£o)
4. src/lib/products/catalog.ts (keywords, pricing)
```

**Tools a usar:**
```
1. Read (4x) - Ler arquivos relevantes
2. Edit OU Write (1x) - Adicionar campanha em 25-GOOGLE-ADS-CAMPANHAS.md
3. Grep (5-10x) - Validar compliance OAB em copy dos anÃºncios
```

**Output esperado:**
```
1. Campanha documentada em 25-GOOGLE-ADS-CAMPANHAS.md
2. 3 grupos de anÃºncios (branded, genÃ©rico, concorrÃªncia)
3. 10-15 keywords negativas
4. Copy validado contra compliance OAB
5. Budget sugerido baseado em demanda
```

**Tempo estimado:** 2-3 horas

**DecisÃ£o: Usar Task tool?**
```
SE criar 1-2 campanhas
  NÃƒO - Executar diretamente
SE criar 5+ campanhas
  SIM - Usar Task tool (CMOAgent + AdsAgent)
```

---

#### 5.3. Criar documentaÃ§Ã£o tÃ©cnica

**Comandos que ativam:**
```
- "crie PRD.md"
- "documente componente X"
- "gere COMPONENT_LIBRARY.md"
- "adicione diagrama de arquitetura"
```

**Arquivos a ler (OBRIGATÃ“RIO):**
```
SE criar PRD.md:
  1. src/app/(marketing)/ (listar pÃ¡ginas via Glob)
  2. src/lib/products/catalog.ts (listar produtos)
  3. .manus/knowledge/produtos-catalogo.md (contexto negÃ³cio)

SE criar COMPONENT_LIBRARY.md:
  1. src/components/ (listar componentes via Glob)
  2. src/components/**/*.tsx (extrair Props via Grep)

SE criar diagrama arquitetura:
  1. src/ (estrutura completa via Bash ls)
  2. .manus/knowledge/tech-stack.md (dependÃªncias)
  3. package.json (stack tecnolÃ³gica)
```

**Tools a usar:**
```
1. Read (5-15x) - Ler arquivos de referÃªncia
2. Glob (2-5x) - Listar componentes/pÃ¡ginas
3. Grep (5-20x) - Extrair Props TypeScript
4. Bash (2-5x) - Comandos ls, tree
5. Write (1x) - Criar documento
```

**Output esperado:**
```
1. Documento criado (PRD.md, COMPONENT_LIBRARY.md, etc)
2. Estrutura padronizada (seÃ§Ãµes, changelog, referÃªncias)
3. InformaÃ§Ã£o 100% alinhada com cÃ³digo
```

**Tempo estimado:** 1-8 horas (varia muito)

**DecisÃ£o: Usar Task tool?**
```
SE documento simples (1-2h esforÃ§o)
  NÃƒO - Executar diretamente
SE documento complexo (4-8h esforÃ§o)
  SIM - Usar Task tool (agent especializado)
```

---

### 6. INFORMAÃ‡ÃƒO

#### 6.1. Responder pergunta sobre projeto

**Comandos que ativam:**
```
- "quantos produtos temos?"
- "qual o score atual?"
- "quais agentes estÃ£o implementados?"
- "lista de pÃ¡ginas criadas"
```

**Arquivos a ler:**
```
SE pergunta sobre produtos:
  1. .manus/knowledge/produtos-catalogo.md
  2. .manus/knowledge/INDEX.md

SE pergunta sobre agentes:
  1. .manus/knowledge/agentes-juridicos.md
  2. .manus/knowledge/INDEX.md

SE pergunta sobre pÃ¡ginas:
  1. .manus/knowledge/pages-implementadas.md
  2. .manus/knowledge/INDEX.md

SE pergunta sobre score:
  1. .manus/knowledge/INDEX.md
  2. .manus/AUDITORIA_COMPLETA_MANUS.md (se existir)
```

**Tools a usar:**
```
1. Read (1-3x) - Ler arquivos relevantes
```

**Output esperado:**
```
Resposta direta com informaÃ§Ã£o extraÃ­da dos arquivos
```

**Tempo estimado:** 1-3 minutos

**DecisÃ£o: Usar Task tool?**
```
NUNCA - Apenas leitura e resposta
```

---

## QUANDO USAR TASK TOOL

### CritÃ©rios objetivos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   USAR TASK TOOL SE:                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  âœ… EsforÃ§o estimado > 4 horas                                          â”‚
â”‚  âœ… Tarefa tem escopo claro e bem definido                              â”‚
â”‚  âœ… MÃºltiplas tarefas independentes (executar em paralelo)              â”‚
â”‚  âœ… UsuÃ¡rio solicitou explicitamente uso de agents                      â”‚
â”‚  âœ… Tarefa requer especializaÃ§Ã£o (ex: CMOAgent, CFOAgent)               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 NÃƒO USAR TASK TOOL SE:                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  âŒ EsforÃ§o estimado < 2 horas                                          â”‚
â”‚  âŒ Tarefa Ã© apenas leitura/anÃ¡lise (nÃ£o criaÃ§Ã£o)                       â”‚
â”‚  âŒ Tarefas sÃ£o interdependentes (precisam executar sequencialmente)    â”‚
â”‚  âŒ Tarefa Ã© auditoria/validaÃ§Ã£o (MANUS faz diretamente)                â”‚
â”‚  âŒ Tarefa Ã© geraÃ§Ã£o de tasks (protocolo task-generation.md)            â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemplos: Usar vs NÃ£o usar

**âœ… USAR Task Tool:**

```markdown
Comando: "Crie pÃ¡ginas para 10 produtos da categoria bancÃ¡rio"

AnÃ¡lise:
- EsforÃ§o: 20h (2h por pÃ¡gina)
- Escopo: Claro (cada pÃ¡gina Ã© independente)
- ParalelizaÃ§Ã£o: PossÃ­vel (10 agents em paralelo)
â†’ USAR Task tool (10 sub-agents)
```

```markdown
Comando: "Crie PRD.md completo com 100+ User Stories"

AnÃ¡lise:
- EsforÃ§o: 8h (anÃ¡lise + escrita)
- Escopo: Claro (estrutura de PRD conhecida)
- EspecializaÃ§Ã£o: Sim (agent PRD)
â†’ USAR Task tool (1 sub-agent especializado)
```

```markdown
Comando: "Crie campanhas Google Ads para top 20 produtos"

AnÃ¡lise:
- EsforÃ§o: 40h (2h por campanha)
- Escopo: Claro (cada campanha Ã© independente)
- ParalelizaÃ§Ã£o: PossÃ­vel (5 agents, 4 campanhas cada)
- EspecializaÃ§Ã£o: Sim (CMOAgent + AdsAgent)
â†’ USAR Task tool (5 sub-agents)
```

---

**âŒ NÃƒO USAR Task Tool:**

```markdown
Comando: "Audite a documentaÃ§Ã£o"

AnÃ¡lise:
- EsforÃ§o: 30-60 min (ANALYZE) + loop completo
- Tipo: Auditoria/anÃ¡lise (nÃ£o criaÃ§Ã£o)
- Protocolo: agent-loop.md (MANUS faz diretamente)
â†’ NÃƒO usar Task tool (MANUS executa Agent Loop)
```

```markdown
Comando: "Gere tasks para prÃ³ximo sprint"

AnÃ¡lise:
- EsforÃ§o: 5-15 min
- Tipo: GeraÃ§Ã£o de tasks (nÃ£o implementaÃ§Ã£o)
- Protocolo: task-generation.md (rÃ¡pido)
â†’ NÃƒO usar Task tool (MANUS gera tasks diretamente)
```

```markdown
Comando: "Valide alinhamento cÃ³digo-docs"

AnÃ¡lise:
- EsforÃ§o: 10-20 min
- Tipo: ValidaÃ§Ã£o (leitura + grep)
- NÃ£o Ã© criaÃ§Ã£o: Apenas anÃ¡lise
â†’ NÃƒO usar Task tool (MANUS faz validaÃ§Ã£o diretamente)
```

```markdown
Comando: "Crie 1 pÃ¡gina para produto seguro-prestamista"

AnÃ¡lise:
- EsforÃ§o: 2h (< 4h)
- Tarefa Ãºnica: Sem paralelizaÃ§Ã£o
â†’ NÃƒO usar Task tool (MANUS cria diretamente)
```

---

### DecisÃ£o em zona cinza (2-4h esforÃ§o)

**Perguntar ao usuÃ¡rio:**

```
MANUS: "Esta tarefa tem esforÃ§o estimado de 3 horas.

Prefere que:
A) Eu execute diretamente (mais rÃ¡pido, vocÃª acompanha)
B) Eu lance um sub-agent (vocÃª pode trabalhar em paralelo)

O que prefere?"
```

---

## FLUXOGRAMAS DE DECISÃƒO

### Fluxograma 1: Classificar comando

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               CLASSIFICAÃ‡ÃƒO DE COMANDO                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTRADA: Comando do usuÃ¡rio
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ContÃ©m palavras: "audite", "verifique alinhamento", "score"?            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ AUDITORIA (agent-loop.md)
    â”‚
    NÃƒO
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ContÃ©m palavras: "gere tasks", "prÃ³ximos passos", "roadmap"?            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ GERAÃ‡ÃƒO TASKS (task-generation.md)
    â”‚
    NÃƒO
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ContÃ©m palavras: "valide", "cross-check", "compliance OAB"?             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ VALIDAÃ‡ÃƒO (execuÃ§Ã£o direta)
    â”‚
    NÃƒO
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ContÃ©m palavras: "implemente", "crie", "adicione"?                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ IMPLEMENTAÃ‡ÃƒO (decisÃ£o: Task tool ou direto?)
    â”‚
    NÃƒO
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰ pergunta? ("quantos", "qual", "lista")                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ INFORMAÃ‡ÃƒO (leitura e resposta)
    â”‚
    NÃƒO
    â”‚
    â–¼
COMANDO NÃƒO RECONHECIDO â†’ Perguntar clarificaÃ§Ã£o ao usuÃ¡rio
```

---

### Fluxograma 2: Decidir usar Task tool

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               DECISÃƒO: USAR TASK TOOL?                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTRADA: Comando de implementaÃ§Ã£o/criaÃ§Ã£o
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EsforÃ§o estimado > 4 horas?                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ MÃºltiplas tarefas independentes?
    â”‚          â”‚
    â”‚          â”œâ”€ SIM â”€â”€â†’ USAR Task tool (N agents em paralelo)
    â”‚          â”‚
    â”‚          NÃƒO
    â”‚          â”‚
    â”‚          â–¼
    â”‚         Escopo bem definido?
    â”‚          â”‚
    â”‚          â”œâ”€ SIM â”€â”€â†’ USAR Task tool (1 agent especializado)
    â”‚          â”‚
    â”‚          NÃƒO â”€â”€â†’ Executar diretamente (iterativo)
    â”‚
    NÃƒO
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EsforÃ§o entre 2-4 horas?                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ SIM â”€â”€â†’ PERGUNTAR ao usuÃ¡rio (A ou B)
    â”‚
    NÃƒO (< 2h)
    â”‚
    â–¼
NÃƒO USAR Task tool (executar diretamente)
```

---

### Fluxograma 3: Auditoria (Agent Loop)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUDITORIA - AGENT LOOP                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTRADA: Comando "audite"
    â”‚
    â–¼
FASE 1: ANALYZE (30-60 min)
    â”‚
    â”œâ”€ Read .manus/knowledge/*.md (6 arquivos)
    â”œâ”€ Glob src/**/*.tsx (listar pÃ¡ginas)
    â”œâ”€ Grep padrÃµes (produtos, agents, etc)
    â”œâ”€ Calcular scores (0-100)
    â”‚
    â–¼
FASE 2: PLAN (15-30 min)
    â”‚
    â”œâ”€ Priorizar P0/P1/P2
    â”œâ”€ Estimar esforÃ§o
    â”œâ”€ Decidir: 1 agent ou N agents?
    â”‚
    â–¼
FASE 3: EXECUTE (2-8h)
    â”‚
    â”œâ”€ SE mÃºltiplos agents
    â”‚   â”‚
    â”‚   â”œâ”€ Task (agent 1, run_in_background: true)
    â”‚   â”œâ”€ Task (agent 2, run_in_background: true)
    â”‚   â””â”€ Task (agent N, run_in_background: true)
    â”‚
    â”œâ”€ SE 1 agent
    â”‚   â”‚
    â”‚   â””â”€ Executar correÃ§Ãµes sequencialmente
    â”‚
    â–¼
FASE 4: OBSERVE (15-30 min)
    â”‚
    â”œâ”€ TaskOutput (agent 1)
    â”œâ”€ TaskOutput (agent 2)
    â”œâ”€ Validar outputs
    â”‚
    â–¼
FASE 5: ITERATE (1-3h)
    â”‚
    â”œâ”€ Score >= 90? â”€â”€SIMâ”€â”€â†’ Pular para DELIVER
    â”‚                  â”‚
    â”‚                  NÃƒO
    â”‚                  â”‚
    â”‚                  â–¼
    â”‚              RelanÃ§ar agents / CorreÃ§Ãµes manuais
    â”‚              â”‚
    â”‚              â””â”€ Voltar para OBSERVE
    â”‚
    â–¼
FASE 6: DELIVER (30-60 min)
    â”‚
    â”œâ”€ Write .manus/VALIDACAO_100_PERCENT.md
    â”œâ”€ Consolidar scores
    â”œâ”€ Gerar changelog
    â”‚
    â–¼
SAÃDA: RelatÃ³rio final + Score X/100
```

---

### Fluxograma 4: Task Generation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TASK GENERATION                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTRADA: Comando "gere tasks"
    â”‚
    â–¼
FASE 1: LEITURA (3-5 min)
    â”‚
    â”œâ”€ Read .manus/knowledge/INDEX.md
    â”œâ”€ Read .manus/knowledge/produtos-catalogo.md
    â”œâ”€ Read .manus/knowledge/pages-implementadas.md
    â”œâ”€ Read .manus/knowledge/agentes-juridicos.md
    â”œâ”€ Read docs/tasks.md (se existir)
    â”‚
    â–¼
FASE 2: ANÃLISE DE GAPS (2-4 min)
    â”‚
    â”œâ”€ Identificar produtos sem pÃ¡gina â†’ [MANUS-PAGES]
    â”œâ”€ Identificar VSLs incompletas â†’ [MANUS-FLOWS]
    â”œâ”€ Identificar produtos sem campanha â†’ [MANUS-ADS]
    â”œâ”€ Identificar docs ausentes â†’ [MANUS-DOCS]
    â”‚
    â–¼
FASE 3: GERAÃ‡ÃƒO (1-2 min)
    â”‚
    â”œâ”€ Para cada gap:
    â”‚   â”‚
    â”‚   â”œâ”€ Gerar ID Ãºnico [CATEGORIA-NNN]
    â”‚   â”œâ”€ TÃ­tulo descritivo
    â”‚   â”œâ”€ Estimar esforÃ§o
    â”‚   â”œâ”€ CritÃ©rios de aceitaÃ§Ã£o (mÃ­n 3)
    â”‚   â””â”€ Arquivos afetados
    â”‚
    â–¼
FASE 4: PRIORIZAÃ‡ÃƒO (1-2 min)
    â”‚
    â”œâ”€ Calcular score de impacto (0-100)
    â”œâ”€ Classificar P0/P1/P2
    â”œâ”€ Ordenar por prioridade
    â”œâ”€ Agrupar por sprint
    â”‚
    â–¼
FASE 5: OUTPUT (1-2 min)
    â”‚
    â”œâ”€ Write docs/tasks.md
    â”œâ”€ Resumo executivo
    â”œâ”€ Roadmap 3 sprints
    â”œâ”€ MÃ©tricas de sucesso
    â”‚
    â–¼
SAÃDA: tasks.md atualizado
```

---

## EXEMPLOS PRÃTICOS

### Exemplo 1: Comando ambÃ­guo

**Comando do usuÃ¡rio:**
```
"Melhore o projeto"
```

**DecisÃ£o de MANUS:**
```
COMANDO AMBÃGUO â†’ Pedir clarificaÃ§Ã£o

MANUS: "Entendi que vocÃª quer melhorar o projeto. Para eu saber como ajudar melhor, vocÃª pode especificar:

A) Auditar documentaÃ§Ã£o (verificar score, gaps, inconsistÃªncias)
B) Gerar tasks para prÃ³ximos passos (roadmap de features)
C) Implementar feature especÃ­fica (qual?)
D) Validar alinhamento cÃ³digo-documentaÃ§Ã£o
E) Outro (especifique)

O que vocÃª prefere?"
```

---

### Exemplo 2: Auditoria simples

**Comando do usuÃ¡rio:**
```
"Audite a documentaÃ§Ã£o"
```

**DecisÃ£o de MANUS:**
```
CLASSIFICAÃ‡ÃƒO: AUDITORIA
PROTOCOLO: agent-loop.md
AÃ‡ÃƒO: Executar Agent Loop (ANALYZE â†’ ... â†’ DELIVER)
```

**SequÃªncia de aÃ§Ãµes:**
```
1. Read .manus/knowledge/INDEX.md
2. Read .manus/knowledge/produtos-catalogo.md
3. Read .manus/knowledge/pages-implementadas.md
4. Read .manus/knowledge/agentes-juridicos.md
5. Read .manus/knowledge/compliance-oab.md
6. Read .manus/knowledge/tech-stack.md
7. Glob "src/app/(marketing)/**/*.tsx"
8. Grep "export const ALL_PRODUCTS" em src/lib/products/catalog.ts
9. Calcular scores
10. Write .manus/AUDITORIA_COMPLETA_MANUS.md
11. Write .manus/GAPS_E_INCONSISTENCIAS.md
12. Responder com resumo
```

**Output:**
```
MANUS: "Auditoria concluÃ­da!

Score atual: 95/100 (EXCELENTE)

Principais achados:
- âœ… 57 produtos implementados e documentados
- âœ… 23 agentes implementados
- âš ï¸ 10 produtos sem documentaÃ§Ã£o completa (P1)
- âš ï¸ 5 VSLs usando defaultVSLConfig (P2)

RelatÃ³rios criados:
- .manus/AUDITORIA_COMPLETA_MANUS.md
- .manus/GAPS_E_INCONSISTENCIAS.md

Deseja que eu gere tasks para resolver os gaps?"
```

---

### Exemplo 3: Criar 1 pÃ¡gina (execuÃ§Ã£o direta)

**Comando do usuÃ¡rio:**
```
"Crie pÃ¡gina para o produto 'CartÃ£o Consignado RMC'"
```

**DecisÃ£o de MANUS:**
```
CLASSIFICAÃ‡ÃƒO: CRIAÃ‡ÃƒO
TIPO: PÃ¡gina de produto
ESFORÃ‡O: 2h (< 4h)
DECISÃƒO: Executar diretamente (NÃƒO usar Task tool)
```

**SequÃªncia de aÃ§Ãµes:**
```
1. Read .manus/knowledge/produtos-catalogo.md
   â†’ Verificar que produto existe
   â†’ Extrair: demanda, ticket, categoria

2. Read src/lib/products/catalog.ts
   â†’ Validar que produto estÃ¡ no catÃ¡logo
   â†’ Slug: "cartao-consignado-rmc"

3. Read src/lib/products/vsl-config.ts
   â†’ Ver padrÃ£o de VSL config

4. Read .manus/knowledge/compliance-oab.md
   â†’ Extrair frases proibidas

5. Edit src/lib/products/vsl-config.ts
   â†’ Adicionar config para "cartao-consignado-rmc"

6. Grep "cartao-consignado" em src/
   â†’ Verificar que nÃ£o hÃ¡ duplicaÃ§Ã£o

7. Validar compliance OAB no copy criado

8. Responder com confirmaÃ§Ã£o
```

**Output:**
```
MANUS: "PÃ¡gina criada com sucesso!

âœ… Produto: CartÃ£o Consignado RMC
âœ… Rota: /solucoes/bancario/cartao-consignado-rmc
âœ… VSL customizada criada
âœ… Compliance OAB validado

Arquivo modificado:
- src/lib/products/vsl-config.ts

PrÃ³ximos passos sugeridos:
1. Testar pÃ¡gina localmente (npm run dev)
2. Criar campanha Google Ads para este produto
3. Otimizar keywords SEO

Deseja que eu faÃ§a algum desses prÃ³ximos passos?"
```

---

### Exemplo 4: Criar 10 pÃ¡ginas (usar Task tool)

**Comando do usuÃ¡rio:**
```
"Crie pÃ¡ginas para os 10 produtos sem documentaÃ§Ã£o completa"
```

**DecisÃ£o de MANUS:**
```
CLASSIFICAÃ‡ÃƒO: CRIAÃ‡ÃƒO
TIPO: MÃºltiplas pÃ¡ginas (10)
ESFORÃ‡O: 20h (2h por pÃ¡gina)
TAREFAS INDEPENDENTES: SIM
DECISÃƒO: Usar Task tool (10 sub-agents em paralelo)
```

**SequÃªncia de aÃ§Ãµes:**
```
1. Read .manus/knowledge/INDEX.md
   â†’ Extrair lista de 10 produtos sem doc:
   ["cartao-consignado-rmc", "busca-apreensao-veiculo", ...]

2. Read .manus/knowledge/produtos-catalogo.md
   â†’ Extrair dados de cada produto

3. Para cada produto, lanÃ§ar sub-agent:

Task({
  description: "Criar pÃ¡gina para cartao-consignado-rmc",
  prompt: `
    VocÃª Ã© um agent especializado em criar pÃ¡ginas de produtos.

    PRODUTO: CartÃ£o Consignado RMC
    DADOS: {dados do produto}

    MISSÃƒO:
    1. Criar VSL config em src/lib/products/vsl-config.ts
    2. Validar compliance OAB
    3. Testar que rota /solucoes/bancario/cartao-consignado-rmc funciona

    CRITÃ‰RIOS:
    - VSL com 9 seÃ§Ãµes completas
    - Copy validado contra compliance OAB
    - Compliance: Zero frases proibidas
  `,
  run_in_background: true
})

4. Aguardar conclusÃ£o de todos os agents (TaskOutput)

5. Validar outputs

6. Responder com resumo
```

**Output:**
```
MANUS: "10 pÃ¡ginas criadas com sucesso!

âœ… cartao-consignado-rmc
âœ… busca-apreensao-veiculo
âœ… vazamento-dados-lgpd
âœ… perfil-hackeado
âœ… problemas-marketplace
âœ… defesa-flagrante
âœ… inquerito-policial
âœ… crimes-transito
âœ… lei-maria-penha
âœ… revisao-criminal

Todas as pÃ¡ginas:
- VSL customizada criada
- Compliance OAB validado
- AcessÃ­veis em /solucoes/{category}/{slug}

Arquivo modificado:
- src/lib/products/vsl-config.ts (10 configs adicionadas)

PrÃ³ximos passos sugeridos:
1. Criar campanhas Google Ads para estes produtos
2. Documentar produtos em CATALOGO_COMPLETO_47_NICHOS.md
3. Testar conversion rate

Deseja que eu faÃ§a algum desses prÃ³ximos passos?"
```

---

### Exemplo 5: Validar compliance OAB

**Comando do usuÃ¡rio:**
```
"Valide se hÃ¡ frases proibidas pela OAB no site"
```

**DecisÃ£o de MANUS:**
```
CLASSIFICAÃ‡ÃƒO: VALIDAÃ‡ÃƒO
TIPO: Compliance OAB
ESFORÃ‡O: 10-15 min
DECISÃƒO: Executar diretamente (validaÃ§Ã£o automÃ¡tica)
```

**SequÃªncia de aÃ§Ãµes:**
```
1. Read .manus/knowledge/compliance-oab.md
   â†’ Extrair 40 frases proibidas

2. Glob "src/app/(marketing)/**/*.tsx"
   â†’ Listar todas as pÃ¡ginas

3. Para cada frase proibida:
   Grep "{frase}" em src/app/(marketing)/ (output_mode: "files_with_matches")

4. Compilar lista de violaÃ§Ãµes (se houver)

5. Write .manus/VALIDACAO_COMPLIANCE_OAB.md

6. Responder com resultado
```

**Output (sem violaÃ§Ãµes):**
```
MANUS: "âœ… ValidaÃ§Ã£o de compliance OAB concluÃ­da!

Status: COMPLIANT (zero violaÃ§Ãµes)

Arquivos validados:
- 57 pÃ¡ginas em src/app/(marketing)/solucoes/
- 1 homepage
- 5 landing pages

Frases proibidas verificadas: 40
ViolaÃ§Ãµes encontradas: 0

RelatÃ³rio criado:
- .manus/VALIDACAO_COMPLIANCE_OAB.md

Seu site estÃ¡ em conformidade com as regras da OAB! âœ…"
```

**Output (com violaÃ§Ãµes):**
```
MANUS: "âš ï¸ ValidaÃ§Ã£o de compliance OAB concluÃ­da!

Status: VIOLAÃ‡Ã•ES ENCONTRADAS

âŒ 3 violaÃ§Ãµes crÃ­ticas:

1. src/app/(marketing)/solucoes/bancario/seguro-prestamista/page.tsx
   Frase proibida: "Garantimos que vocÃª vai ganhar"
   Linha: 45

2. src/app/(marketing)/solucoes/previdenciario/bpc-loas/page.tsx
   Frase proibida: "Resolvemos em 30 dias"
   Linha: 67

3. docs/24-LANDING-PAGE-PRINCIPAL.md
   Frase proibida: "Melhor advogado do Brasil"
   Linha: 123

AÃ‡ÃƒO OBRIGATÃ“RIA:
Corrija IMEDIATAMENTE estas violaÃ§Ãµes antes de lanÃ§ar o site.

RelatÃ³rio completo:
- .manus/VALIDACAO_COMPLIANCE_OAB.md

Deseja que eu corrija automaticamente?"
```

---

### Exemplo 6: Gerar tasks apÃ³s auditoria

**Comando do usuÃ¡rio:**
```
"Gere tasks para prÃ³ximo sprint"
```

**DecisÃ£o de MANUS:**
```
CLASSIFICAÃ‡ÃƒO: GERAÃ‡ÃƒO DE TASKS
PROTOCOLO: task-generation.md
ESFORÃ‡O: 5-15 min
DECISÃƒO: Executar diretamente (NÃƒO usar Task tool)
```

**SequÃªncia de aÃ§Ãµes:**
```
1. LEITURA (3-5 min)
   Read .manus/knowledge/INDEX.md
   Read .manus/knowledge/produtos-catalogo.md
   Read .manus/knowledge/pages-implementadas.md
   Read docs/tasks.md

2. ANÃLISE DE GAPS (2-4 min)
   Identificar:
   - 10 produtos sem pÃ¡gina
   - 15 VSLs incompletas
   - 20 produtos sem campanha Ads
   - 5 docs ausentes

3. GERAÃ‡ÃƒO (1-2 min)
   Gerar 50 tasks distribuÃ­das em 4 categorias

4. PRIORIZAÃ‡ÃƒO (1-2 min)
   P0: 2 tasks
   P1: 20 tasks
   P2: 28 tasks

5. OUTPUT (1-2 min)
   Write docs/tasks.md
```

**Output:**
```
MANUS: "Tasks geradas com sucesso!

Total: 50 tasks
- P0 (CrÃ­tico): 2
- P1 (Alta): 20
- P2 (MÃ©dia): 28

DistribuiÃ§Ã£o por categoria:
- [MANUS-PAGES]: 10 tasks (20h)
- [MANUS-FLOWS]: 15 tasks (30h)
- [MANUS-ADS]: 20 tasks (40h)
- [MANUS-DOCS]: 5 tasks (10h)

EsforÃ§o total: 100h (5 sprints de 20h)

Roadmap sugerido:

Sprint 1 (Semana 1): 2 P0 + 8 P1 (18h)
- Corrigir violaÃ§Ãµes compliance OAB
- Criar pÃ¡ginas para top 5 produtos

Sprint 2 (Semana 2): 12 P1 (22h)
- Completar VSLs prioritÃ¡rias
- Criar campanhas Ads top 10 produtos

Sprint 3-5: Tasks P2 (60h)

Arquivo criado:
- docs/tasks.md

Ver detalhes completos em docs/tasks.md

Deseja que eu comece executando Sprint 1?"
```

---

## CHECKLIST FINAL

### Antes de executar aÃ§Ã£o

- [ ] Comando foi classificado corretamente (auditoria/implementaÃ§Ã£o/geraÃ§Ã£o/validaÃ§Ã£o/informaÃ§Ã£o)
- [ ] Arquivos obrigatÃ³rios foram identificados (knowledge/, code, docs)
- [ ] Tools a usar foram selecionadas (Read, Glob, Grep, Edit, Write, Task)
- [ ] DecisÃ£o de usar/nÃ£o usar Task tool foi tomada (baseada em critÃ©rios objetivos)
- [ ] Output esperado estÃ¡ claro

### Durante a execuÃ§Ã£o

- [ ] Todos os arquivos obrigatÃ³rios foram lidos
- [ ] Tools foram usadas na ordem correta
- [ ] ValidaÃ§Ãµes foram feitas (compliance OAB, alinhamento, etc)
- [ ] Outputs parciais foram salvos
- [ ] TodoWrite atualizada (se aplicÃ¡vel)

### ApÃ³s executar aÃ§Ã£o

- [ ] Output esperado foi gerado
- [ ] DocumentaÃ§Ã£o foi atualizada (se aplicÃ¡vel)
- [ ] Changelog foi criado/atualizado
- [ ] PrÃ³ximos passos foram sugeridos ao usuÃ¡rio
- [ ] UsuÃ¡rio recebeu confirmaÃ§Ã£o clara do que foi feito

---

**VersÃ£o do protocolo:** 1.0
**MANUS:** v7.0
**Data:** 29/12/2025
**Status:** âœ… COMPLETO E PRONTO PARA USO
