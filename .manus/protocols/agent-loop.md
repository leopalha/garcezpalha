# PROTOCOLO: Agent Loop MANUS v7.0

**Vers√£o**: 1.0
**Data**: 29/12/2025
**Sistema**: MANUS v7.0 (Multi-Agent Network for Unified Systems)
**Projeto**: Garcez Palha - Advocacia Digital

---

## √çNDICE

1. [Vis√£o Geral](#vis√£o-geral)
2. [As 6 Fases do Loop](#as-6-fases-do-loop)
3. [Sistema de Scoring](#sistema-de-scoring)
4. [Sistema de Prioriza√ß√£o](#sistema-de-prioriza√ß√£o)
5. [Fluxo Completo](#fluxo-completo)
6. [Ferramentas por Fase](#ferramentas-por-fase)
7. [Boas Pr√°ticas](#boas-pr√°ticas)
8. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## VIS√ÉO GERAL

### O que √© o Agent Loop?

O **Agent Loop** √© o ciclo de execu√ß√£o fundamental do MANUS v7.0. Ele define como MANUS:
- Analisa problemas de documenta√ß√£o
- Planeja solu√ß√µes
- Executa corre√ß√µes
- Monitora progresso
- Itera para melhorar
- Entrega resultados consolidados

### Quando usar este protocolo?

**SEMPRE** que MANUS for ativado para:
- Auditar documenta√ß√£o
- Corrigir inconsist√™ncias
- Implementar features documentadas
- Validar alinhamento c√≥digo ‚Üî documenta√ß√£o
- Gerar relat√≥rios de qualidade

### Princ√≠pios fundamentais

1. **Ler antes de agir**: Nunca proponha mudan√ßas sem ler o estado atual
2. **Medir objetivamente**: Use scoring 0-100 em TODAS as avalia√ß√µes
3. **Priorizar bloqueadores**: P0 primeiro, sempre
4. **Executar em paralelo**: Agents trabalham simultaneamente quando poss√≠vel
5. **Iterar continuamente**: Re-avaliar ap√≥s cada execu√ß√£o
6. **Documentar tudo**: Cada mudan√ßa gera changelog

---

## AS 6 FASES DO LOOP

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        MANUS v7.0 AGENT LOOP                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ  1. ANALYZE (An√°lise)        ‚è±Ô∏è  30-60 min                               ‚îÇ
‚îÇ  2. PLAN (Planejamento)      ‚è±Ô∏è  15-30 min                               ‚îÇ
‚îÇ  3. EXECUTE (Execu√ß√£o)       ‚è±Ô∏è  2-8 horas                               ‚îÇ
‚îÇ  4. OBSERVE (Observa√ß√£o)     ‚è±Ô∏è  15-30 min                               ‚îÇ
‚îÇ  5. ITERATE (Itera√ß√£o)       ‚è±Ô∏è  1-3 horas                               ‚îÇ
‚îÇ  6. DELIVER (Entrega)        ‚è±Ô∏è  30-60 min                               ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  Total: 5-14 horas (sess√£o completa)                                   ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## FASE 1: ANALYZE (An√°lise)

### Objetivo

Entender o estado atual do projeto e identificar todos os problemas de documenta√ß√£o.

### Tempo estimado

**30-60 minutos** (dependendo do tamanho do projeto)

### A√ß√µes obrigat√≥rias

1. **Ler TODOS os documentos relevantes**
   - `.manus/knowledge/` (todos os arquivos .md)
   - `docs/` (documenta√ß√£o legacy)
   - `business/` (documenta√ß√£o t√©cnica)
   - `README.md` (overview)

2. **Analisar c√≥digo-fonte**
   - `src/lib/products/catalog.ts` (cat√°logo de produtos)
   - `src/lib/ai/agents/` (agentes IA)
   - `src/app/(marketing)/` (p√°ginas implementadas)
   - `package.json` (depend√™ncias)

3. **Identificar gaps e inconsist√™ncias**
   - Documenta√ß√£o menciona feature n√£o implementada
   - C√≥digo implementa feature n√£o documentada
   - Informa√ß√µes duplicadas em m√∫ltiplos arquivos
   - Informa√ß√µes conflitantes entre documentos
   - Documenta√ß√£o desatualizada

4. **Criar matriz de problemas**
   - Classificar cada problema como P0/P1/P2
   - Estimar esfor√ßo de corre√ß√£o
   - Identificar depend√™ncias entre problemas
   - Calcular score de cada documento (0-100)

### Tools usadas

| Tool | Uso | Exemplo |
|------|-----|---------|
| **Read** | Ler documentos | `Read("d:/garcezpalha/docs/21_EMPRESA.md")` |
| **Glob** | Listar arquivos por padr√£o | `Glob("**/*.md")` |
| **Grep** | Buscar padr√µes no c√≥digo | `Grep("export const ALL_PRODUCTS", type: "ts")` |
| **Bash** | Comandos git, ls, wc | `git status`, `wc -l docs/*.md` |

### Outputs esperados

1. **Relat√≥rio de auditoria**
   - Arquivo: `.manus/AUDITORIA_COMPLETA_MANUS.md`
   - Conte√∫do: Tabela de scores, falhas cr√≠ticas, gaps

2. **Matriz de problemas**
   - Arquivo: `.manus/GAPS_E_INCONSISTENCIAS.md`
   - Conte√∫do: Lista priorizada de problemas (P0/P1/P2)

3. **Score geral do projeto**
   - M√©trica: 0-100 (m√©dia ponderada de todos os documentos)
   - Classifica√ß√£o: CR√çTICO / ACEIT√ÅVEL / BOM / EXCELENTE

### Exemplo de output

```markdown
## RESUMO EXECUTIVO

| Documento | Tamanho | Score | Status | Prioridade |
|-----------|---------|-------|--------|------------|
| INDEX.md | 392 linhas | 95/100 | ‚úÖ EXCELENTE | - |
| produtos-catalogo.md | 653 linhas | 90/100 | ‚úÖ EXCELENTE | - |
| compliance-oab.md | 450 linhas | 85/100 | ‚ö†Ô∏è BOM | P1 |
| pages-implementadas.md | 700 linhas | 92/100 | ‚úÖ EXCELENTE | - |

**Score M√©dio:** 90.5/100
**Classifica√ß√£o:** EXCELENTE (pronto para investidores)

## FALHAS CR√çTICAS (P0)

Nenhuma encontrada ‚úÖ

## GAPS DE INFORMA√á√ÉO (P1)

1. **[P1-001] 10 produtos sem documenta√ß√£o completa**
   - Produtos: cartao-consignado-rmc, busca-apreensao-veiculo, etc
   - Impacto: M√©dio (n√£o bloqueia, mas reduz qualidade)
   - Esfor√ßo: 4-6 horas
   - Solu√ß√£o: Adicionar estes produtos em CATALOGO_COMPLETO_47_NICHOS.md
```

### Crit√©rios de sucesso

- [ ] Todos os documentos em `.manus/knowledge/` foram lidos
- [ ] C√≥digo-fonte foi analisado (produtos, agents, p√°ginas)
- [ ] Matriz de problemas foi criada com P0/P1/P2
- [ ] Score foi calculado para cada documento
- [ ] Score geral do projeto foi calculado
- [ ] Relat√≥rios foram salvos em `.manus/`

---

## FASE 2: PLAN (Planejamento)

### Objetivo

Criar um plano de a√ß√£o priorizado e execut√°vel para corrigir todos os problemas identificados.

### Tempo estimado

**15-30 minutos**

### A√ß√µes obrigat√≥rias

1. **Priorizar corre√ß√µes**
   - P0 primeiro (bloqueadores cr√≠ticos)
   - P1 depois (alta prioridade)
   - P2 no final (melhorias)

2. **Estimar esfor√ßo**
   - Tempo de leitura
   - Tempo de an√°lise
   - Tempo de escrita/edi√ß√£o
   - Total em horas

3. **Criar roadmap de execu√ß√£o**
   - Fases sequenciais (quando h√° depend√™ncias)
   - Fases paralelas (quando independentes)
   - Checkpoints de valida√ß√£o

4. **Alocar agents**
   - Determinar se precisa de m√∫ltiplos agents
   - Definir escopo de cada agent
   - Estimar quando lan√ßar em paralelo

### Tools usadas

| Tool | Uso | Exemplo |
|------|-----|---------|
| **Write** | Criar plano de execu√ß√£o | `Write(".manus/PLANO_EXECUCAO.md", content)` |
| **TodoWrite** | Criar lista de tarefas | `TodoWrite([{content: "Corrigir P0-001", status: "pending"}])` |

### Outputs esperados

1. **Plano de execu√ß√£o**
   - Arquivo: `.manus/PLANO_EXECUCAO_100_PERCENT.md`
   - Conte√∫do: Fases, esfor√ßo, agents alocados

2. **Lista de tarefas**
   - Ferramenta: TodoWrite
   - Conte√∫do: Tarefas priorizadas com status

### Estrutura do plano

```markdown
## FASES DE CORRE√á√ÉO

### FASE 1: Quick Wins (2h)
**Objetivo:** Resolver bloqueadores P0

**Tarefas:**
- [P0-001] Criar PRD.md ausente (1h)
- [P0-002] Atualizar status de features implementadas (30min)
- [P0-003] Remover refer√™ncias a p√°ginas deletadas (30min)

**Agents:** 1 agent sequencial
**Esfor√ßo total:** 2h

---

### FASE 2: Documenta√ß√£o T√©cnica (6h)
**Objetivo:** Completar docs t√©cnicos

**Tarefas:**
- [P1-001] Documentar 10 produtos extras (4h)
- [P1-002] Adicionar diagramas de arquitetura (2h)

**Agents:** 2 agents em paralelo
**Esfor√ßo total:** 4h real (6h de trabalho)

---

### FASE 3: Melhorias (3h)
**Objetivo:** Refinamentos P2

**Tarefas:**
- [P2-001] Atualizar keywords SEO (1h)
- [P2-002] Adicionar exemplos de uso (2h)

**Agents:** 1 agent sequencial
**Esfor√ßo total:** 3h
```

### Crit√©rios de decis√£o: 1 agent vs m√∫ltiplos agents

**Use 1 AGENT quando:**
- Tarefas s√£o interdependentes
- Esfor√ßo total < 2 horas
- N√£o h√° paraleliza√ß√£o poss√≠vel
- Precisa de contexto compartilhado

**Use M√öLTIPLOS AGENTS quando:**
- Tarefas s√£o independentes
- Esfor√ßo total > 4 horas
- Paraleliza√ß√£o √© poss√≠vel
- Cada agent tem escopo claro

### Crit√©rios de sucesso

- [ ] Plano criado com fases claras
- [ ] Esfor√ßo estimado para cada fase
- [ ] Prioriza√ß√£o P0 ‚Üí P1 ‚Üí P2 respeitada
- [ ] Decis√£o de 1 vs N agents tomada e justificada
- [ ] TodoWrite atualizada com tarefas

---

## FASE 3: EXECUTE (Execu√ß√£o)

### Objetivo

Executar o plano criado, lan√ßando agents especializados em paralelo quando poss√≠vel.

### Tempo estimado

**2-8 horas** (varia muito com complexidade)

### A√ß√µes obrigat√≥rias

1. **Lan√ßar agents em paralelo (se aplic√°vel)**
   - Usar Task tool para criar sub-agents
   - Passar contexto claro para cada agent
   - Definir crit√©rios de sucesso objetivos

2. **Executar corre√ß√µes sequenciais**
   - Bloqueadores P0 primeiro
   - Validar cada corre√ß√£o antes de pr√≥xima
   - Atualizar TodoWrite ap√≥s cada tarefa

3. **Spawnar sub-agents se necess√°rio**
   - Se um agent encontrar complexidade inesperada
   - Se precisa de especializa√ß√£o (ex: agent SEO, agent OAB)

4. **Monitorar progresso**
   - Verificar outputs parciais
   - Identificar bloqueadores em tempo real
   - Ajustar plano se necess√°rio

### Tools usadas

| Tool | Uso | Exemplo |
|------|-----|---------|
| **Task** | Lan√ßar sub-agents | `Task({description: "Documentar produtos", prompt: "...", run_in_background: true})` |
| **Edit** | Editar documentos existentes | `Edit(file_path, old_string, new_string)` |
| **Write** | Criar novos documentos | `Write(file_path, content)` |
| **TodoWrite** | Atualizar progresso | `TodoWrite([{content: "...", status: "in_progress"}])` |

### Como lan√ßar agents em paralelo

```typescript
// Exemplo: Lan√ßar 3 agents para corrigir diferentes documentos

// Agent 1: Atualizar PRD
Task({
  description: "FASE 1: Atualizar PRD completo",
  prompt: `
    Voc√™ √© um agent especializado em Product Requirements Documents.

    CONTEXTO:
    - Projeto: Garcez Palha (advocacia digital)
    - Arquivo: d:/garcezpalha/business/PRD.md

    MISS√ÉO:
    1. Ler business/PRD.md atual
    2. Comparar com c√≥digo em src/app/(marketing)/
    3. Marcar features implementadas como ‚úÖ IMPLEMENTADO
    4. Adicionar User Stories para p√°ginas em src/app/(marketing)/ n√£o documentadas
    5. Remover refer√™ncias a p√°ginas deletadas

    CRIT√âRIOS DE SUCESSO:
    - PRD deve refletir 100% o c√≥digo atual
    - Todas as p√°ginas em src/app/(marketing)/ devem ter User Story
    - Nenhuma refer√™ncia a p√°ginas inexistentes
    - Score final: 90+/100

    TOOLS OBRIGAT√ìRIAS:
    - Read para ler PRD.md
    - Glob/Grep para listar p√°ginas
    - Edit para atualizar PRD.md
    - Write para criar changelog

    IMPORTANTE:
    - N√ÉO crie novos arquivos sem necessidade
    - SEMPRE use Read antes de Edit
    - Atualize changelog ao final
  `,
  subagent_type: "general-purpose",
  run_in_background: true
})

// Agent 2: Documentar componentes
Task({
  description: "FASE 2: Criar COMPONENT_LIBRARY.md",
  prompt: `
    Voc√™ √© um agent especializado em documenta√ß√£o de componentes React.

    CONTEXTO:
    - Projeto: Garcez Palha (Next.js 14 + React 19)
    - Componentes: src/components/

    MISS√ÉO:
    1. Listar TODOS os componentes em src/components/
    2. Criar business/COMPONENT_LIBRARY.md
    3. Para cada componente documentar:
       - Props TypeScript
       - Descri√ß√£o
       - Exemplo de uso
       - Screenshot (se aplic√°vel)

    CRIT√âRIOS DE SUCESSO:
    - Todos os componentes em src/components/ documentados
    - Props extra√≠dos do TypeScript
    - Exemplos de uso funcionais
    - Score final: 90+/100
  `,
  subagent_type: "general-purpose",
  run_in_background: true
})

// Agent 3: Validar marketing
Task({
  description: "FASE 3: Cross-check marketing",
  prompt: `
    Voc√™ √© um agent de valida√ß√£o de consist√™ncia.

    MISS√ÉO:
    1. Ler .manus/knowledge/produtos-catalogo.md
    2. Ler .manus/knowledge/pages-implementadas.md
    3. Validar que:
       - Todos os produtos documentados t√™m p√°gina implementada
       - Todas as p√°ginas implementadas t√™m produto documentado
       - Nenhuma inconsist√™ncia entre docs

    CRIT√âRIOS DE SUCESSO:
    - Zero inconsist√™ncias encontradas
    - Gerar relat√≥rio .manus/VALIDACAO_MARKETING.md
    - Score final: 100/100
  `,
  subagent_type: "general-purpose",
  run_in_background: true
})
```

### Como monitorar agents em background

**N√ÉO use TaskOutput imediatamente** - deixe os agents trabalharem.

Aguarde alguns minutos e ent√£o:

```typescript
// Verificar progresso do Agent 1
TaskOutput({ task_id: "agent_1_id" })

// Se ainda n√£o terminou, aguardar mais
// Se terminou, validar output e marcar tarefa como conclu√≠da

TodoWrite([
  { content: "Atualizar PRD completo", status: "completed", activeForm: "Atualizando PRD completo" }
])
```

### Crit√©rios de sucesso

- [ ] Todos os agents foram lan√ßados conforme plano
- [ ] Agents receberam contexto claro e objetivos
- [ ] Agents foram monitorados e n√£o falharam
- [ ] Outputs de agents foram validados
- [ ] TodoWrite foi atualizada em tempo real
- [ ] Documentos foram criados/editados corretamente

---

## FASE 4: OBSERVE (Observa√ß√£o)

### Objetivo

Monitorar progresso dos agents, validar outputs parciais e identificar bloqueadores.

### Tempo estimado

**15-30 minutos**

### A√ß√µes obrigat√≥rias

1. **Monitorar progresso dos agents**
   - Usar TaskOutput para verificar status
   - Ler outputs parciais gerados
   - Validar que agents est√£o seguindo instru√ß√µes

2. **Validar outputs parciais**
   - Ler arquivos criados/editados
   - Verificar qualidade (score 0-100)
   - Identificar se atende crit√©rios de sucesso

3. **Identificar bloqueadores em tempo real**
   - Agent est√° travado?
   - Agent est√° fazendo a√ß√£o errada?
   - Agent precisa de mais contexto?

4. **Tomar a√ß√µes corretivas**
   - Parar agent se necess√°rio
   - Relan√ßar com instru√ß√µes corrigidas
   - Fazer corre√ß√£o manual se agent falhou

### Tools usadas

| Tool | Uso | Exemplo |
|------|-----|---------|
| **TaskOutput** | Verificar progresso de agent | `TaskOutput({ task_id: "id", block: false })` |
| **Read** | Validar outputs gerados | `Read(".manus/arquivo_gerado.md")` |
| **TodoWrite** | Atualizar status de tarefas | `TodoWrite([{content: "...", status: "in_progress"}])` |

### Exemplos de valida√ß√£o

**Validar que agent criou arquivo correto:**

```typescript
// Ler output do agent
const output = Read("d:/garcezpalha/business/PRD.md")

// Validar conte√∫do
if (!output.includes("## 2. USER STORIES")) {
  // Relan√ßar agent com instru√ß√µes corrigidas
  Task({
    description: "CORRE√á√ÉO: Adicionar se√ß√£o User Stories ao PRD",
    prompt: "..."
  })
}
```

**Validar que agent atualizou status corretamente:**

```typescript
// Verificar se features implementadas foram marcadas
const prd = Read("d:/garcezpalha/business/PRD.md")

// Buscar pattern "‚úÖ IMPLEMENTADO"
const implemented = Grep("‚úÖ IMPLEMENTADO", path: "business/PRD.md", output_mode: "count")

// Se < 30, agent falhou
if (implemented.count < 30) {
  // Corre√ß√£o manual ou relan√ßar
}
```

### Crit√©rios de sucesso

- [ ] Todos os agents foram monitorados
- [ ] Outputs parciais foram validados
- [ ] Bloqueadores foram identificados e resolvidos
- [ ] TodoWrite reflete estado real do progresso
- [ ] Nenhum agent est√° travado ou fazendo a√ß√£o errada

---

## FASE 5: ITERATE (Itera√ß√£o)

### Objetivo

Ajustar plano baseado em descobertas, relan√ßar agents para corre√ß√µes adicionais e fazer cross-check.

### Tempo estimado

**1-3 horas**

### A√ß√µes obrigat√≥rias

1. **Ajustar plano baseado em descobertas**
   - Se agents encontraram mais problemas que o esperado
   - Se algumas corre√ß√µes n√£o foram suficientes
   - Se novos gaps foram identificados

2. **Relan√ßar agents para corre√ß√µes adicionais**
   - Agents que falharam
   - Agents que precisam de refinamento
   - Novos agents para problemas inesperados

3. **Cross-check entre documentos**
   - Validar consist√™ncia entre todos os docs
   - Verificar que nenhuma duplica√ß√£o foi criada
   - Garantir que refer√™ncias cruzadas est√£o corretas

4. **Re-calcular scores**
   - Score de cada documento atualizado
   - Score geral do projeto atualizado
   - Comparar com score inicial (melhoria %)

### Tools usadas

| Tool | Uso | Exemplo |
|------|-----|---------|
| **Read** | Re-validar documentos | `Read(".manus/knowledge/INDEX.md")` |
| **Grep** | Buscar inconsist√™ncias | `Grep("PENDENTE", path: ".manus/knowledge/", output_mode: "count")` |
| **Edit** | Corre√ß√µes manuais finas | `Edit(file_path, old_string, new_string)` |
| **Task** | Relan√ßar agents | `Task({...})` |

### Exemplo de itera√ß√£o

```markdown
## ITERA√á√ÉO 1: Ap√≥s execu√ß√£o dos 3 agents

**Descobertas:**
1. Agent PRD criou PRD.md mas esqueceu 5 User Stories
2. Agent COMPONENT_LIBRARY documentou componentes, mas faltou extrair Props
3. Agent VALIDA√á√ÉO encontrou 3 inconsist√™ncias n√£o previstas

**A√ß√µes corretivas:**

1. **Relan√ßar Agent PRD** (foco nas 5 User Stories faltantes)
   - Tempo: 30 min
   - Crit√©rio: PRD.md deve ter 100% das p√°ginas

2. **Corre√ß√£o manual em COMPONENT_LIBRARY**
   - Usar Grep para extrair Props TypeScript
   - Editar COMPONENT_LIBRARY.md manualmente
   - Tempo: 1h

3. **Relan√ßar Agent VALIDA√á√ÉO** (ap√≥s corre√ß√µes 1 e 2)
   - Tempo: 15 min
   - Crit√©rio: Zero inconsist√™ncias

**Score atualizado:**
- PRD.md: 75/100 ‚Üí 90/100 (ap√≥s corre√ß√£o)
- COMPONENT_LIBRARY.md: 80/100 ‚Üí 95/100 (ap√≥s corre√ß√£o)
- VALIDA√á√ÉO: 85/100 ‚Üí 100/100 (ap√≥s corre√ß√£o)

**Score geral:** 72/100 ‚Üí 92/100 (melhoria de 28%)
```

### Crit√©rios de sucesso

- [ ] Todos os problemas identificados na OBSERVE foram resolvidos
- [ ] Cross-check completo foi feito
- [ ] Scores foram re-calculados
- [ ] Score geral do projeto aumentou (ou j√° est√° 90+)
- [ ] Nenhuma inconsist√™ncia remanescente

---

## FASE 6: DELIVER (Entrega)

### Objetivo

Consolidar todos os outputs dos agents, criar relat√≥rio final e atualizar scores.

### Tempo estimado

**30-60 minutos**

### A√ß√µes obrigat√≥rias

1. **Consolidar outputs dos agents**
   - Ler todos os arquivos gerados/editados
   - Validar que todos est√£o no padr√£o MANUS
   - Verificar changelogs atualizados

2. **Criar relat√≥rio final de auditoria**
   - Arquivo: `.manus/VALIDACAO_100_PERCENT.md`
   - Conte√∫do: Scores antes/depois, mudan√ßas realizadas, pr√≥ximos passos

3. **Atualizar scores de qualidade**
   - Score de cada documento (0-100)
   - Score geral do projeto (0-100)
   - Classifica√ß√£o (CR√çTICO/ACEIT√ÅVEL/BOM/EXCELENTE)

4. **Gerar changelog completo**
   - O que foi mudado
   - Por que foi mudado
   - Impacto da mudan√ßa
   - Pr√≥ximos passos

### Tools usadas

| Tool | Uso | Exemplo |
|------|-----|---------|
| **Write** | Criar relat√≥rio final | `Write(".manus/VALIDACAO_100_PERCENT.md", content)` |
| **Read** | Validar documentos finais | `Read(".manus/knowledge/INDEX.md")` |
| **TodoWrite** | Finalizar tarefas | `TodoWrite([{content: "...", status: "completed"}])` |
| **Bash** | Commit git (se solicitado) | `git add . && git commit -m "..."` |

### Estrutura do relat√≥rio final

```markdown
# VALIDA√á√ÉO 100% - GARCEZ PALHA

**Projeto:** Garcez Palha - Advocacia Digital
**Data:** 29/12/2025
**Respons√°vel:** MANUS v7.0
**Dura√ß√£o:** 8 horas

---

## RESUMO EXECUTIVO

### Scores Antes vs Depois

| Documento | Antes | Depois | Melhoria |
|-----------|-------|--------|----------|
| INDEX.md | 85/100 | 95/100 | +10 pts |
| produtos-catalogo.md | 80/100 | 90/100 | +10 pts |
| compliance-oab.md | 75/100 | 85/100 | +10 pts |
| pages-implementadas.md | 82/100 | 92/100 | +10 pts |

**Score Geral:** 80.5/100 ‚Üí 90.5/100 (+10 pts)
**Classifica√ß√£o:** BOM ‚Üí EXCELENTE

---

## MUDAN√áAS REALIZADAS

### FASE 1: Quick Wins (2h)
‚úÖ [P0-001] Criado PRD.md completo (1h)
‚úÖ [P0-002] Atualizado status de 35 features implementadas (30min)
‚úÖ [P0-003] Removidas 5 refer√™ncias a p√°ginas deletadas (30min)

### FASE 2: Documenta√ß√£o T√©cnica (6h ‚Üí 4h real)
‚úÖ [P1-001] Documentados 10 produtos extras em CATALOGO_COMPLETO.md (4h)
‚úÖ [P1-002] Criado COMPONENT_LIBRARY.md com 47 componentes (2h)

### FASE 3: Melhorias (3h)
‚úÖ [P2-001] Atualizadas keywords SEO em 57 p√°ginas (1h)
‚úÖ [P2-002] Adicionados exemplos de uso em COMPONENT_LIBRARY.md (2h)

**Total de mudan√ßas:** 57 arquivos editados, 3 arquivos criados

---

## IMPACTO

### Qualidade de Documenta√ß√£o
- **Antes:** 80.5/100 (BOM)
- **Depois:** 90.5/100 (EXCELENTE)
- **Melhoria:** +12.4%

### Alinhamento C√≥digo ‚Üî Documenta√ß√£o
- **Antes:** 78% alinhado (22 gaps)
- **Depois:** 98% alinhado (2 gaps menores)
- **Melhoria:** +20 pontos percentuais

### Prontid√£o para Investidores
- **Antes:** ‚ö†Ô∏è Precisa melhorias
- **Depois:** ‚úÖ Pronto para apresenta√ß√£o

---

## PR√ìXIMOS PASSOS

### Prioridade P0 (Cr√≠tico)
Nenhuma ‚úÖ

### Prioridade P1 (Alta)
- [ ] Adicionar screenshots em COMPONENT_LIBRARY.md (2h)
- [ ] Criar diagramas de arquitetura em ASCII (3h)

### Prioridade P2 (M√©dia)
- [ ] Traduzir documenta√ß√£o chave para ingl√™s (8h)
- [ ] Criar v√≠deos demo de cada produto (20h)

### Manuten√ß√£o Cont√≠nua
- [ ] Rodar auditoria MANUS a cada sprint (1h/sprint)
- [ ] Atualizar documenta√ß√£o a cada nova feature
- [ ] Manter score 90+/100 sempre

---

## CHANGELOG

### v1.0 - 29/12/2025
- ‚úÖ Auditoria completa realizada (8 horas)
- ‚úÖ 60 mudan√ßas implementadas
- ‚úÖ Score melhorado de 80.5 para 90.5
- ‚úÖ Documenta√ß√£o pronta para investidores

---

**Gerado por MANUS v7.0**
**Autor:** Claude Sonnet 4.5
```

### Crit√©rios de sucesso

- [ ] Relat√≥rio final criado em `.manus/VALIDACAO_100_PERCENT.md`
- [ ] Scores finais calculados e documentados
- [ ] Changelog completo gerado
- [ ] Pr√≥ximos passos priorizados (P0/P1/P2)
- [ ] TodoWrite finalizada (todas as tarefas "completed")
- [ ] Commit git criado (se solicitado pelo usu√°rio)

---

## SISTEMA DE SCORING

### Escala 0-100

| Score | Classifica√ß√£o | Descri√ß√£o | A√ß√£o |
|-------|--------------|-----------|------|
| **90-100** | ‚úÖ EXCELENTE | Pronto para investidores. Documenta√ß√£o completa, atualizada, sem gaps. | Manter |
| **80-89** | ‚ö†Ô∏è BOM | Pequenas melhorias necess√°rias. Maioria das informa√ß√µes est√° correta. | Melhorar P1 |
| **70-79** | ‚ö†Ô∏è ACEIT√ÅVEL | Precisa melhorias. Gaps significativos ou informa√ß√µes desatualizadas. | Melhorar P0+P1 |
| **60-69** | ‚ùå PRECISA MELHORIAS | Gaps significativos. Informa√ß√£o cr√≠tica ausente ou incorreta. | Sprint emergencial |
| **0-59** | ‚ùå CR√çTICO | Bloqueadores graves. Documenta√ß√£o in√∫til ou perigosamente incorreta. | Refazer do zero |

### Como calcular score de um documento

**Crit√©rios de avalia√ß√£o (peso igual):**

1. **Completude** (0-25 pontos)
   - 25: Todas as se√ß√µes esperadas existem
   - 20: Falta 1 se√ß√£o importante
   - 15: Faltam 2-3 se√ß√µes importantes
   - 10: Faltam 4+ se√ß√µes
   - 0: Documento vazio ou in√∫til

2. **Precis√£o** (0-25 pontos)
   - 25: 100% alinhado com c√≥digo/realidade
   - 20: 1-2 informa√ß√µes desatualizadas
   - 15: 3-5 informa√ß√µes desatualizadas
   - 10: 6-10 informa√ß√µes desatualizadas
   - 0: Maioria das informa√ß√µes incorretas

3. **Consist√™ncia** (0-25 pontos)
   - 25: Zero conflitos com outros documentos
   - 20: 1-2 conflitos menores
   - 15: 3-5 conflitos
   - 10: 6-10 conflitos
   - 0: Conflitos graves em toda parte

4. **Utilidade** (0-25 pontos)
   - 25: Documento √© auto-explicativo, actionable
   - 20: Precisa de 1-2 complementos
   - 15: Precisa de 3-5 complementos
   - 10: Precisa de muita contextualiza√ß√£o
   - 0: Documento n√£o √© √∫til

**Score final = Completude + Precis√£o + Consist√™ncia + Utilidade**

### Exemplo de c√°lculo

```markdown
Documento: `.manus/knowledge/produtos-catalogo.md`

**Avalia√ß√£o:**

1. Completude: 25/25
   - Todas as se√ß√µes esperadas existem
   - √çndice, resumo, produtos por categoria, mapeamento agent‚Üíproduto

2. Precis√£o: 20/25
   - 57 produtos documentados, mas c√≥digo tem 57 tamb√©m ‚úÖ
   - 10 produtos sem descri√ß√£o completa ‚ùå
   - Pre√ßos desatualizados em 2 produtos ‚ùå

3. Consist√™ncia: 25/25
   - Zero conflitos com pages-implementadas.md ‚úÖ
   - Zero conflitos com agentes-juridicos.md ‚úÖ

4. Utilidade: 20/25
   - Documento √© √∫til, mas faltam exemplos pr√°ticos ‚ùå
   - Faltam CTAs para cada produto ‚ùå

**Score final:** 25 + 20 + 25 + 20 = 90/100 (EXCELENTE)
```

### Como calcular score geral do projeto

**M√©dia ponderada:**

```
Score Geral = (Score_Doc1 * Peso1 + Score_Doc2 * Peso2 + ...) / Soma_Pesos
```

**Pesos recomendados:**

| Documento | Peso | Justificativa |
|-----------|------|---------------|
| INDEX.md | 3 | Entrada principal |
| produtos-catalogo.md | 3 | Core business |
| agentes-juridicos.md | 2 | Diferencial t√©cnico |
| compliance-oab.md | 3 | Cr√≠tico (legal) |
| pages-implementadas.md | 2 | Valida√ß√£o t√©cnica |
| tech-stack.md | 1 | Informa√ß√£o t√©cnica |

**Exemplo:**

```
Score Geral = (95*3 + 90*3 + 85*2 + 85*3 + 92*2 + 88*1) / (3+3+2+3+2+1)
            = (285 + 270 + 170 + 255 + 184 + 88) / 14
            = 1252 / 14
            = 89.4/100
            ‚âà 90/100 (EXCELENTE)
```

---

## SISTEMA DE PRIORIZA√á√ÉO

### Defini√ß√µes

**P0 (Bloqueador Cr√≠tico):**
- **Impacto:** Impede desenvolvimento, lan√ßamento ou vendas
- **Urg√™ncia:** IMEDIATO (0-24h)
- **Exemplos:**
  - Informa√ß√£o cr√≠tica ausente (ex: pre√ßo de produto principal)
  - Inconsist√™ncia grave (doc diz X, c√≥digo faz Y)
  - Viola√ß√£o compliance OAB (pode gerar processo √©tico)
  - Documenta√ß√£o que induz erro grave

**P1 (Alta Prioridade):**
- **Impacto:** Afeta qualidade, compreens√£o ou velocidade
- **Urg√™ncia:** 1-3 dias
- **Exemplos:**
  - Informa√ß√£o importante incompleta
  - Gaps de documenta√ß√£o (produto sem doc)
  - Duplica√ß√£o de informa√ß√£o
  - Documenta√ß√£o desatualizada (mas n√£o cr√≠tica)

**P2 (Melhoria):**
- **Impacto:** Refinamento, detalhamento, polish
- **Urg√™ncia:** Quando poss√≠vel (1-2 semanas)
- **Exemplos:**
  - Adicionar exemplos pr√°ticos
  - Melhorar formata√ß√£o
  - Adicionar diagramas
  - Documenta√ß√£o complementar (nice to have)

### Matriz de prioriza√ß√£o

```
         ‚îÇ Alto Impacto ‚îÇ M√©dio Impacto ‚îÇ Baixo Impacto ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Alta     ‚îÇ     P0       ‚îÇ      P1       ‚îÇ      P1       ‚îÇ
Urg√™ncia ‚îÇ              ‚îÇ               ‚îÇ               ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
M√©dia    ‚îÇ     P1       ‚îÇ      P1       ‚îÇ      P2       ‚îÇ
Urg√™ncia ‚îÇ              ‚îÇ               ‚îÇ               ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Baixa    ‚îÇ     P1       ‚îÇ      P2       ‚îÇ      P2       ‚îÇ
Urg√™ncia ‚îÇ              ‚îÇ               ‚îÇ               ‚îÇ
```

### Como priorizar um problema

**Pergunte:**

1. **Bloqueia algo cr√≠tico?** (desenvolvimento, vendas, compliance)
   - SIM ‚Üí P0
   - N√ÉO ‚Üí continue

2. **Afeta qualidade significativamente?**
   - SIM ‚Üí P1
   - N√ÉO ‚Üí continue

3. **√â refinamento/polish?**
   - SIM ‚Üí P2

### Exemplos pr√°ticos

```markdown
[P0-001] Pre√ßo do produto "Seguro Prestamista" est√° errado
- Impacto: ALTO (cliente pode processar por propaganda enganosa)
- Urg√™ncia: IMEDIATO (produto est√° no ar)
- Prioridade: P0

[P1-001] 10 produtos sem documenta√ß√£o completa
- Impacto: M√âDIO (afeta qualidade, mas n√£o bloqueia)
- Urg√™ncia: M√âDIA (melhorar em 1-3 dias)
- Prioridade: P1

[P2-001] Adicionar diagramas ASCII em tech-stack.md
- Impacto: BAIXO (melhora compreens√£o, mas n√£o cr√≠tico)
- Urg√™ncia: BAIXA (quando poss√≠vel)
- Prioridade: P2
```

---

## FLUXO COMPLETO

### Diagrama de fluxo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     AGENT LOOP - FLUXO COMPLETO                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  START
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. ANALYZE     ‚îÇ  ‚è±Ô∏è 30-60 min
‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Ler docs      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚Ä¢ Ler c√≥digo    ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Identificar   ‚îÇ      ‚îÇ
‚îÇ   gaps          ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Calcular      ‚îÇ      ‚îÇ
‚îÇ   scores        ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
    ‚îÇ                    ‚îÇ
    ‚ñº                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  2. PLAN        ‚îÇ  ‚è±Ô∏è 15-30 min
‚îÇ                 ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Priorizar P0  ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Estimar       ‚îÇ      ‚îÇ
‚îÇ   esfor√ßo       ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Criar roadmap ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Alocar agents ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
    ‚îÇ                    ‚îÇ
    ‚ñº                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  3. EXECUTE     ‚îÇ  ‚è±Ô∏è 2-8 horas
‚îÇ                 ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Lan√ßar agents ‚îÇ      ‚îÇ
‚îÇ   em paralelo   ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Executar      ‚îÇ      ‚îÇ
‚îÇ   corre√ß√µes     ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Spawnar       ‚îÇ      ‚îÇ
‚îÇ   sub-agents    ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
    ‚îÇ                    ‚îÇ
    ‚ñº                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  4. OBSERVE     ‚îÇ  ‚è±Ô∏è 15-30 min
‚îÇ                 ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Monitorar     ‚îÇ      ‚îÇ
‚îÇ   progresso     ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Validar       ‚îÇ      ‚îÇ
‚îÇ   outputs       ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Identificar   ‚îÇ      ‚îÇ
‚îÇ   bloqueadores  ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
    ‚îÇ                    ‚îÇ
    ‚ñº                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  5. ITERATE     ‚îÇ  ‚è±Ô∏è 1-3 horas
‚îÇ                 ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Ajustar plano ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Relan√ßar      ‚îÇ      ‚îÇ
‚îÇ   agents        ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Cross-check   ‚îÇ      ‚îÇ
‚îÇ ‚Ä¢ Re-calcular   ‚îÇ      ‚îÇ
‚îÇ   scores        ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
    ‚îÇ                    ‚îÇ
    ‚îÇ  Score < 90?       ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄYES‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ                (volta para ANALYZE)
    NO
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. DELIVER     ‚îÇ  ‚è±Ô∏è 30-60 min
‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Consolidar    ‚îÇ
‚îÇ   outputs       ‚îÇ
‚îÇ ‚Ä¢ Criar         ‚îÇ
‚îÇ   relat√≥rio     ‚îÇ
‚îÇ ‚Ä¢ Atualizar     ‚îÇ
‚îÇ   scores        ‚îÇ
‚îÇ ‚Ä¢ Gerar         ‚îÇ
‚îÇ   changelog     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
  END (Score 90+/100)
```

### Decis√µes cr√≠ticas no fluxo

**Decis√£o 1: Quantos agents lan√ßar?**
- Local: FASE 2 (PLAN)
- Crit√©rio: Tarefas independentes E esfor√ßo total > 4h ‚Üí m√∫ltiplos agents
- Crit√©rio: Tarefas interdependentes OU esfor√ßo < 2h ‚Üí 1 agent

**Decis√£o 2: Quando iterar?**
- Local: FASE 5 (ITERATE)
- Crit√©rio: Score < 90 ‚Üí iterar
- Crit√©rio: Score >= 90 ‚Üí entregar
- Crit√©rio: Score < 70 ‚Üí iterar 2-3 vezes

**Decis√£o 3: Quando parar de iterar?**
- Local: FASE 5 (ITERATE)
- Crit√©rio: Score >= 90 ‚Üí parar
- Crit√©rio: Itera√ß√µes >= 3 E score n√£o melhorou ‚Üí parar (problema estrutural)
- Crit√©rio: Tempo > 12 horas ‚Üí parar (dividir em 2 sess√µes)

---

## FERRAMENTAS POR FASE

### FASE 1: ANALYZE

| Tool | Uso | Frequ√™ncia |
|------|-----|------------|
| Read | Ler documentos | 10-20 vezes |
| Glob | Listar arquivos | 3-5 vezes |
| Grep | Buscar padr√µes | 5-10 vezes |
| Bash | Git status, ls, wc | 2-5 vezes |

### FASE 2: PLAN

| Tool | Uso | Frequ√™ncia |
|------|-----|------------|
| Write | Criar plano | 1 vez |
| TodoWrite | Criar tasks | 1 vez |

### FASE 3: EXECUTE

| Tool | Uso | Frequ√™ncia |
|------|-----|------------|
| Task | Lan√ßar sub-agents | 1-5 vezes |
| Edit | Editar documentos | 10-50 vezes |
| Write | Criar documentos | 1-5 vezes |
| TodoWrite | Atualizar progresso | 5-20 vezes |

### FASE 4: OBSERVE

| Tool | Uso | Frequ√™ncia |
|------|-----|------------|
| TaskOutput | Verificar agents | 3-10 vezes |
| Read | Validar outputs | 5-15 vezes |
| TodoWrite | Atualizar status | 3-10 vezes |

### FASE 5: ITERATE

| Tool | Uso | Frequ√™ncia |
|------|-----|------------|
| Read | Re-validar docs | 5-15 vezes |
| Grep | Buscar inconsist√™ncias | 3-8 vezes |
| Edit | Corre√ß√µes finas | 5-20 vezes |
| Task | Relan√ßar agents | 0-3 vezes |

### FASE 6: DELIVER

| Tool | Uso | Frequ√™ncia |
|------|-----|------------|
| Write | Criar relat√≥rio final | 1 vez |
| Read | Validar documentos finais | 3-8 vezes |
| TodoWrite | Finalizar tasks | 1 vez |
| Bash | Git commit (opcional) | 0-1 vez |

---

## BOAS PR√ÅTICAS

### 1. SEMPRE ler antes de escrever

**ERRADO:**
```typescript
Write("d:/garcezpalha/docs/PRD.md", "# PRD...")
```

**CORRETO:**
```typescript
const current = Read("d:/garcezpalha/docs/PRD.md")
if (current) {
  Edit("d:/garcezpalha/docs/PRD.md", old_string, new_string)
} else {
  Write("d:/garcezpalha/docs/PRD.md", content)
}
```

### 2. Manter changelog atualizado

**SEMPRE adicionar ao final do documento:**

```markdown
## CHANGELOG

### v1.2 - 29/12/2025
- ‚úÖ Adicionados 10 produtos extras
- ‚úÖ Atualizado mapeamento agent‚Üíproduto
- ‚úÖ Corrigidos 5 pre√ßos desatualizados

### v1.1 - 28/12/2025
- ‚úÖ Primeira vers√£o completa
```

### 3. Cross-references s√£o obrigat√≥rios

**Ao mencionar outro documento:**

```markdown
Ver detalhes completos em [produtos-catalogo.md](./produtos-catalogo.md)
```

**N√ÉO fazer:**
```markdown
Ver produtos-catalogo.md
```

### 4. Evitar duplica√ß√£o

**ERRADO:** Copiar informa√ß√£o de um doc para outro

**CORRETO:** Criar fonte √∫nica de verdade (SSOT) e referenciar

```markdown
# INDEX.md
Total de produtos: 57

Ver cat√°logo completo em [produtos-catalogo.md](./produtos-catalogo.md)
```

### 5. ASCII art > Mermaid

**PREFERIR:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Agent 1   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Agent 2   ‚îÇ‚îÄ‚ñ∂‚îÇ Output  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**EM VEZ DE:**
```mermaid
graph LR
  A[Agent 1] --> C[Output]
  B[Agent 2] --> C
```

**Raz√£o:** ASCII versiona melhor em git e renderiza em qualquer editor

### 6. Marcar TODOs claramente

```markdown
- ‚è≥ PENDENTE - N√£o implementado
- üîÑ EM ANDAMENTO - Sendo implementado
- ‚úÖ IMPLEMENTADO - Pronto e testado
- ‚ùå CANCELADO - N√£o ser√° feito
```

### 7. Usar scores objetivos

**ERRADO:**
```markdown
A documenta√ß√£o est√° boa.
```

**CORRETO:**
```markdown
Score: 85/100 (BOM - pequenas melhorias necess√°rias)
```

### 8. Atualizar TodoWrite em tempo real

**N√ÉO esperar todas as tarefas finalizarem:**

```typescript
// Ao iniciar tarefa
TodoWrite([{
  content: "Documentar 10 produtos extras",
  status: "in_progress",
  activeForm: "Documentando 10 produtos extras"
}])

// Ao finalizar tarefa
TodoWrite([{
  content: "Documentar 10 produtos extras",
  status: "completed",
  activeForm: "Documentando 10 produtos extras"
}])
```

### 9. Validar outputs de agents

**SEMPRE ler o que o agent criou:**

```typescript
// Lan√ßar agent
Task({...})

// Aguardar
// ...

// Validar output
const output = Read(".manus/arquivo_gerado.md")
if (!output.includes("SE√á√ÉO ESPERADA")) {
  // Relan√ßar ou corrigir manualmente
}
```

### 10. Commits git descritivos

**ERRADO:**
```bash
git commit -m "updates"
```

**CORRETO:**
```bash
git commit -m "docs: MANUS v7.0 - Auditoria completa (60 mudan√ßas, score 80‚Üí90)"
```

---

## EXEMPLOS PR√ÅTICOS

### Exemplo 1: Auditoria simples (score j√° alto)

```markdown
CONTEXTO:
- Projeto: Garcez Palha
- Documenta√ß√£o: 5 arquivos em .manus/knowledge/
- Score atual: Desconhecido

SESS√ÉO:

1. ANALYZE (30 min)
   - Ler 5 arquivos .md
   - Calcular scores
   - Resultado: Score m√©dio 92/100 (EXCELENTE)

2. PLAN (10 min)
   - Nenhum P0 encontrado
   - 2 gaps P1 (faltam exemplos pr√°ticos)
   - Decis√£o: Corre√ß√£o manual (n√£o precisa agents)

3. EXECUTE (1h)
   - Adicionar exemplos em 2 documentos
   - Atualizar changelogs

4. OBSERVE (10 min)
   - Validar que exemplos foram adicionados
   - Score atualizado: 95/100

5. ITERATE (skip)
   - Score j√° 95/100, n√£o precisa iterar

6. DELIVER (20 min)
   - Criar relat√≥rio final
   - Score: 92 ‚Üí 95 (+3 pontos)

RESULTADO:
- Dura√ß√£o: 2h 10min
- Mudan√ßas: 2 documentos editados
- Score final: 95/100 (EXCELENTE)
```

### Exemplo 2: Auditoria complexa (score baixo, m√∫ltiplos agents)

```markdown
CONTEXTO:
- Projeto: Garcez Palha
- Documenta√ß√£o: 15 arquivos desatualizados
- Score estimado: 60-70/100 (PRECISA MELHORIAS)

SESS√ÉO:

1. ANALYZE (60 min)
   - Ler 15 arquivos .md
   - Ler c√≥digo-fonte (products, agents, pages)
   - Identificar 45 gaps
   - Calcular scores
   - Resultado: Score m√©dio 68/100 (PRECISA MELHORIAS)

2. PLAN (30 min)
   - 8 bloqueadores P0 (informa√ß√µes cr√≠ticas ausentes)
   - 22 gaps P1 (documenta√ß√£o incompleta)
   - 15 melhorias P2 (refinamentos)
   - Decis√£o: Lan√ßar 4 agents em paralelo

3. EXECUTE (6h ‚Üí 4h real)
   - Agent 1: Corrigir P0 em INDEX.md e produtos-catalogo.md (2h)
   - Agent 2: Criar COMPONENT_LIBRARY.md (2h)
   - Agent 3: Atualizar pages-implementadas.md (1h)
   - Agent 4: Cross-check compliance OAB (1h)

4. OBSERVE (30 min)
   - Agent 1: ‚úÖ Sucesso (score 68‚Üí85)
   - Agent 2: ‚ö†Ô∏è Faltou documentar 10 componentes
   - Agent 3: ‚úÖ Sucesso (score 72‚Üí90)
   - Agent 4: ‚úÖ Sucesso (score 75‚Üí88)

5. ITERATE (2h)
   - Relan√ßar Agent 2 para completar 10 componentes (1h)
   - Corre√ß√£o manual de 5 P1 remanescentes (1h)
   - Re-calcular scores
   - Resultado: Score m√©dio 91/100 (EXCELENTE)

6. DELIVER (45 min)
   - Consolidar outputs
   - Criar relat√≥rio final
   - Score: 68 ‚Üí 91 (+23 pontos)
   - Atualizar TodoWrite

RESULTADO:
- Dura√ß√£o: 10h 15min
- Mudan√ßas: 47 arquivos editados, 3 arquivos criados
- Score final: 91/100 (EXCELENTE)
- Pronto para investidores ‚úÖ
```

### Exemplo 3: Manuten√ß√£o cont√≠nua (ap√≥s sprint)

```markdown
CONTEXTO:
- Projeto: Garcez Palha
- Situa√ß√£o: Sprint finalizado, 5 features implementadas
- Objetivo: Manter documenta√ß√£o sincronizada

SESS√ÉO:

1. ANALYZE (15 min)
   - Ler git log para identificar features implementadas
   - Ler documenta√ß√£o atual
   - Identificar gaps (features n√£o documentadas)
   - Resultado: 5 features implementadas n√£o documentadas

2. PLAN (10 min)
   - Atualizar PRD.md (marcar 5 features como ‚úÖ)
   - Atualizar COMPONENT_LIBRARY.md (3 novos componentes)
   - Atualizar pages-implementadas.md (2 novas p√°ginas)
   - Decis√£o: Corre√ß√£o sequencial (interdependente)

3. EXECUTE (1h)
   - Atualizar PRD.md (30 min)
   - Atualizar COMPONENT_LIBRARY.md (20 min)
   - Atualizar pages-implementadas.md (10 min)

4. OBSERVE (10 min)
   - Validar que todas as 5 features foram documentadas
   - Score mantido: 92/100

5. ITERATE (skip)
   - Score mantido, n√£o precisa iterar

6. DELIVER (15 min)
   - Criar changelog de sprint
   - Commit git

RESULTADO:
- Dura√ß√£o: 1h 50min
- Mudan√ßas: 3 documentos atualizados
- Score: 92/100 (mantido)
- Documenta√ß√£o 100% alinhada com c√≥digo ‚úÖ
```

---

## TROUBLESHOOTING

### Problema: Agent est√° travado

**Sintomas:**
- TaskOutput n√£o retorna nada ap√≥s 30+ minutos
- Agent n√£o gera outputs esperados

**Solu√ß√µes:**
1. Verificar se prompt est√° claro e objetivo
2. Relan√ßar agent com instru√ß√µes mais simples
3. Dividir tarefa em 2 agents menores
4. Fazer corre√ß√£o manual se agent falhou 2+ vezes

### Problema: Score n√£o est√° melhorando

**Sintomas:**
- Ap√≥s 2+ itera√ß√µes, score continua < 80

**Solu√ß√µes:**
1. Re-analisar crit√©rios de score (pode estar muito rigoroso)
2. Identificar se problema √© estrutural (n√£o corrig√≠vel rapidamente)
3. Dividir em 2 sess√µes (focar P0+P1 agora, P2 depois)
4. Consultar usu√°rio se crit√©rios de score est√£o corretos

### Problema: Muitos gaps P0

**Sintomas:**
- ANALYZE identifica 15+ gaps P0

**Solu√ß√µes:**
1. Re-classificar (alguns podem ser P1)
2. Dividir em sprints (Sprint Emergencial para 50% dos P0)
3. Lan√ßar mais agents em paralelo (5-8 agents)
4. Consultar usu√°rio se todos s√£o realmente bloqueadores

### Problema: Agents gerando duplica√ß√£o

**Sintomas:**
- M√∫ltiplos agents criando informa√ß√£o duplicada

**Solu√ß√µes:**
1. Definir SSOT (Single Source of Truth) mais claramente
2. Instruir agents a SEMPRE referenciar, n√£o copiar
3. Fazer cross-check manual ap√≥s execu√ß√£o
4. Relan√ßar agents para consolidar duplica√ß√µes

---

## CHECKLIST FINAL

### Antes de iniciar sess√£o

- [ ] ACTIVATION_PROMPT lido e compreendido
- [ ] Objetivo da sess√£o est√° claro (auditoria, corre√ß√£o, valida√ß√£o)
- [ ] Tempo dispon√≠vel √© suficiente (m√≠nimo 2h para auditoria simples)
- [ ] TodoWrite est√° limpa (ou criada)

### Durante a sess√£o

- [ ] ANALYZE completo (todos os docs lidos)
- [ ] Scores calculados objetivamente (0-100)
- [ ] PLAN criado com fases claras
- [ ] Agents lan√ßados conforme plano
- [ ] Outputs validados em OBSERVE
- [ ] ITERATE realizado se score < 90
- [ ] TodoWrite atualizada em tempo real

### Ao finalizar sess√£o

- [ ] Relat√≥rio final criado
- [ ] Scores antes/depois documentados
- [ ] Changelog completo gerado
- [ ] Pr√≥ximos passos priorizados (P0/P1/P2)
- [ ] TodoWrite finalizada (todas as tarefas "completed")
- [ ] Commit git criado (se solicitado)
- [ ] Score geral >= 90/100 OU plano claro para pr√≥xima sess√£o

---

**Vers√£o do protocolo:** 1.0
**MANUS:** v7.0
**Data:** 29/12/2025
**Status:** ‚úÖ COMPLETO E PRONTO PARA USO
